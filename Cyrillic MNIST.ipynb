{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e49735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d27e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08de608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4198fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.enabled)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceecfc6",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66cbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = []\n",
    "letter = []\n",
    "dirName = './dataset_mnist'\n",
    "for path, subdirs, files in os.walk(dirName):\n",
    "    for name in files:\n",
    "        letter.append(path[-3])\n",
    "        if path[-3] == 'o':\n",
    "            print(path)\n",
    "        path_list.append(os.path.join(path, name))\n",
    "        \n",
    "        #dataset[os.path.join(path, name)] = path[-3]\n",
    "        #print(os.path.join(path, name))\n",
    "        #print(path[-3])\n",
    "#print(dataset)\n",
    "#print(path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e2a6d5",
   "metadata": {},
   "source": [
    "## Showcase data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda44af",
   "metadata": {},
   "source": [
    "## Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc09745",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = []\n",
    "test_letters = []\n",
    "#test_images = []\n",
    "train_path = []\n",
    "train_letters = []\n",
    "#train_images = []\n",
    "for i in range(len(path_list)):\n",
    "    if (i % 3 == 0):\n",
    "        test_path.append(path_list[i])\n",
    "        test_letters.append(letter[i])\n",
    "        #test_images = io.imread(path_list[i])\n",
    "    else:\n",
    "        train_path.append(path_list[i])\n",
    "        train_letters.append(letter[i])\n",
    "        #train_images = io.imread(path_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a5b826",
   "metadata": {},
   "source": [
    "# Building Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85dce2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lettersIndex = ['А', 'Б', 'В', 'Г', 'Ґ', 'Д', 'Е', 'Є', 'Ж', 'З', 'И', 'І', 'Ї', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ч', 'Ц', 'Ч', 'Ш', 'Щ', 'Ь', 'Ю', 'Я']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03d078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "\n",
    "class MNISTCyrDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"MNIST cyrillics dataset\"\"\"\n",
    "\n",
    "    def __init__(self, file_paths, file_letters, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.file_letters = file_letters\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.file_paths[idx]\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        sample = [image, lettersIndex.index(self.file_letters[idx])]\n",
    "        if self.transform:\n",
    "            sample[0] = self.transform(sample[0])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "725d0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = MNISTCyrDataset(file_paths=test_path, file_letters=test_letters, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,), (0.5,)),\n",
    "                               torchvision.transforms.Grayscale(1),\n",
    "                               torchvision.transforms.Resize((32, 32))\n",
    "                             ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c606f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTCyrDataset(file_paths=train_path, file_letters=train_letters, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,), (0.5,)),\n",
    "                               torchvision.transforms.Grayscale(1),\n",
    "                               torchvision.transforms.Resize((32, 32))\n",
    "                             ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(test_dataset, 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64370a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image , label = train_dataset[32]\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b324c684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAACRCAYAAABqpQfbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYi0lEQVR4nO2de7AVRZLGv1IeAgryUgHFi4AI+EAFRhAXjQBdHPWO+AjXt4Myxro746yCRugsqMD42EWXXTVWWUdl1cFRY33LjiOOoTC+WIUBkVFEBxCRxxURBJTaP865RVbKKbr79jl1z+X7RdyIbLJPd3V3dSeVmZVlrLUghBBCYrBH7AYQQgjZfaERIoQQEg0aIUIIIdGgESKEEBINGiFCCCHRoBEihBASjSZvhIwxNcYYa4xpFuHcy4wxIyp9XpIv7EMkT9iffHIxQsaY84wxbxpjvjHGrC7Kf2+MMXkcv1wYYzaKv+3GmM1i+4KUx3rQGDMpx7Z1McY8Y4xZWeywNSX262CM+dIY83pe544B+1CcPmSMGWGMmVe878uNMefmdf6YsD+VpT8ZY8wNxpjPjDEbjDG/Nca0behxG2yEjDHXAPg3AHcAOADA/gCuBHA8gBYlfrNnQ8+bB9bavev/AHwG4HTxb4/U7xfjfywAtgN4CcBZu9jvNgAflL855YN9qGwE+5Axph+ARwHcAKAdgKMAvFux1pUJ9qeycTGAi1C4j10BtALw7w0+qrU28x8KHfcbAGftYr8HAdwL4IXi/iMA9AXwKoA6AAsBnCH2fxXA5WL7UgCvi22LQqf6S/H3dwMwRd2eAP4FwBoASwFcVdy/2S7auAzAiKJ8IoDlAK4DsArADN0G0Y5eAMYC2AZgK4CNAJ4Vx7wWwHwAXwGYCWCvlPe4WfE8NTvRDQUwF8Blum3V8sc+FK8PoWCAbondB9ifqqM/AXgCwDixPRTAtwBaN+SZNXQkNARASwBPJ9j3fACTAewD4E0AzwL4XwD7AfhHAI8YY/qkOPdpAAYBOBLAuQBOKf77FUXd0QAGAjg7xTElBwDoAOBgFB5oSay19wF4BMDttvA/ltOF+lwAfwugR7Gtl9YrjDF1xphhWRpX/J/bfwD4BxQ6XrXCPoQ4fQjAccVjLDDGfG6M+W9jTIeMx2ossD+hrP3JKLklgN4pruEHNNQIdQKwxlr7nWuVMXOKF7LZGPM3Yt+nrbVvWGu3AxgAYG8At1prt1prXwHwHIC/S3HuW621ddbazwDMLh4TKNzgu6y1f7XWrgPw64zXth3ABGvtFmvt5ozHAIBp1tqVxbY8K9oJa+2+1tqssZyfA3jTWlvt7hP2oV1Trj50IArulbNQ+JDk416JC/vTrsnan14CcHkxsaIdCqMyAGjdgLagoX7FtQA6GWOa1T90a+1QADDGLIdv5P4q5K4A/lp8+PV8CqBbinOvEvImFDqQO7Y6bha+tNZ+m/G3Et3Org09oDGmKwpG6NiGHqsRwD60a3LvQ0U2A/iNtXYJABhjpgB4Oadjx4L9addk7U8PADgIBddkMwD/CuB0FNyEmWnoSGgugC0AahPsK11GKwEcZIyR5+8OYEVR/ga+dT0gRZs+R+FGyeNmQbu4vDYZY3SbKukSGwygC4BFxphVKARhBxtjVjWWAGsK2IdK719u5qtzVrNbtx72p9L7Nwhr7XZr7QRrbY219kAU4mYrsOMeZaJBRshaWwfgJgD3GGPONsbsY4zZwxgzAECbwE/fRMECjzfGNDfGnIiCRf1tUf8egNHGmNbGmF4AxqRo1uMAfm6MOdAY0x7A9Sl+G+J9AP2NMQOMMXsBmKj0XwA4JKdzAQCK52lZ3GxZ3AaAFwHUoDCMHgDgnwH8H4AB1trv82xDuWEf8qhkHwKA3wC4zBhziDGmNQrX+Vye56807E8eufYnU5gO0rOYqt0PwFQAN6vRY2oanKJtrb0dwD8BGI/CRX8B4D9R8BfOKfGbrSg84FEoZIzcA+Bia+3i4i53opDV8QWAh1AIsCXlfgCzUHhA8wA8le6Kdk7RZXEzCu6KvwDQftP/AtCv6Hv+nyTHLOb+nxDYZTMKmS0AsLi4jaJPeFX9HwpZLtuKctXBPuSoWB8qtucBAA+j8AH+FIURxM+TnLcxw/7kyLs/dcKObMIXATxQTIBoEPUphIQQQkjFafJlewghhDReaIQIIYREg0aIEEJINGiECCGERINGiBBCSDRSVUzo1KmTrampKVNTSDlZtmwZ1qxZE7WMPftP9cL+QxpCqP+kMkI1NTV455138mkVqSgDBw6M3QSv/2zf7s9vM2KZF1PhJV/0NAV5/tAUhjTtlMfJen2hdpYDeb5BgwaV9VxJ4Penegl9f2KsSZE7+uVM+sJX+iNCdrDHHr4nWN7fNAbq+++/L6mT58hqTEK6UL/T6OvNQl79Lum9YD8nlYAxIUIIIdGgESKEEBINGiFCCCHRaBIxIe27zsOXXekgMNlBmue5557JVq7QxwjFoGT8RutCx0wa90lTr7Ec/S6UeCFjbEnvLSENgSMhQggh0aARIoQQEo2qdcclTZlOMweE6amVI427M2lKcZpjJn3WaVKrk7ZTu/iSur3SXN9XX33l5Pnz53u6b7/dsUK0nvzZu3fvkucjpBxwJEQIISQaNEKEEEKiQSNECCEkGlUbE0oas2Fpnuoja4mdNWvWeNtz5851soyRAMBhhx3m5LzqoiXtM6EYUJo4Zai/fvLJJ06eMGGCp/vwww+dPHLkSE83duxYJw8dOrRkOwnJC46ECCGERINGiBBCSDSq1h2XFbrcGj8ht1OIFStWeNvTpk1z8rx58zyddDVdccUVnq62tjbR+SpB1jRp+btt27Z5ulWrVjn55Zdf9nTt2rVzMt1xpBJwJEQIISQaNEKEEEKiQSNECCEkGlUbE6qrq3Pyp59+6um+++47Jx966KGerlWrVk7WqbKMEZWf+lhF1hVL05TYkeVx1q9f7+leeeUVJ+tY0tKlS508ZswYT9e2bduS509KXmnYW7dudfLy5cs93f333+/kjz/+2NPJ+6LjRbKkD8v2kErAkRAhhJBo0AgRQgiJRnR3nHQNpKlYvGDBAidPnTrV033++edO1u6UESNGOLlbt26erkWLFiXPx9TufMhy7+RvpAsKAJYsWeLkSZMmeTpdPVqyefNmJ2t31e9//3snX3jhhekamzOh+yXdztod9/zzzztZpmRr9DsnXdTs59mQCwPOmTPH023atMnJIbdzmur/xx13nJPbt29f8ndpqOT3jiMhQggh0aARIoQQEg0aIUIIIdHIHBPKWulYE4oDyXiRTqN96623dioDfjXlp59+2tPJlSM7d+7s6Zo3b16yLfSP50OSFO2QTvrbAf9Zv/32255u7dq1idok40MA8Kc//cnJ1113nae7/vrrnazT/0OUw8cu3w+ZWg3490m/q126dHHy6NGjPd1VV12VS9t2J3SFdhlTvOOOOzzd6tWrndy/f39P17NnTyfr6SPy+c6ePdvTPfjgg04++uijPZ38pqXpd5X83nEkRAghJBo0QoQQQqKR2R1XjuGadhtIV92sWbM83fTp052sU1Bbtmzp5EsuucTTHXHEEU5u06aNpwulQZJ8qL/HMr0Y8J91yEWr3XGhBeKSotuyYcMGJ3/wwQee7uuvvy55nFCKbZrpB6XQVR9effVVJ//iF7/wdF988UXJ48iqIQcffLCn69Onj5P5DpRG3hu5gCAAjBs3zsnaPSZduGeeeaanO+GEE5ysQwNy2smTTz7p6bQrVhL6psntULWRPPpuCI6ECCGERINGiBBCSDRohAghhEQjdUwoSxVkSZoqwRJdrkWm1e69996e7sQTT3Ryr169PJ2MA6VJE2bZnnzRfuak9zTku86KPnfW2GCoGnYe6NiVTA3WUxiyTqEo9zU0FeS96dixo6c799xznXz11Vd7Orlvs2b+51f2bf38ZLmfvfbay9NlLbUU6iPljgN556rYmQghhBAFjRAhhJBopHbH1Q/3tBsk6zA+qVtPp+LKFMauXbt6uhtvvNHJelayHALrBb1CLjc9dCbZqE+xzppaLdOLAWD48OFO/t3vfufprr32WifrhQ9HjRrl5H79+nk66ULRqbJZXVTyfUnjBpYp6bqyg0wlz8Mtuau27c6E0psPOuggTzdlyhQna7eW/OboEINEpmQD/hSVc845x9PJ71/IjaafrXwHQ1W7yw1HQoQQQqJBI0QIISQaNEKEEEKikTnQkTWFT/uuQ8fZsmXLTmVN69atve1QyqI8n66+Lasw65I+P/7xj5283377eTr60ZNTKhaUdVXJb775xsk67rNx48aS7ZBprvp5ylI2+hhyBVOd/t+2bduS58v6vsjzPfroo55u8uTJJX+XtFwLS/NkI/TOy2etyzw99dRTTtblfmT8Ucc+ZUx64sSJni7ptJMQ+ncs20MIIWS3gEaIEEJINMpSMSGEHtqF0qJfe+01J8+ZM8fTdejQwcky3RbwF+3Sw2GZIvniiy96Ork4lHbRHHXUUU7Wi+HRHZec+mF+qGJCqFqFrhj87rvvOnn8+PGebunSpU4+5JBDPF2nTp2cfPLJJ3s66aobO3asp7vlllucrF3LZ5xxhpPTuDCSpm/rlF7pitTIe6Zdyz169HBy9+7dE7dzdybUJ/VzkenVM2bM8HQPPfSQk5ctW+bpfvSjHzlZLy5YW1vrZO2qy6t6jYQVEwghhOwW0AgRQgiJBo0QIYSQaGQu21MJ5MqR7733nqc75phjnHz22Wd7OllteObMmZ5OpkUuXrzY08lq3LoUh1ytlWQnb1+zfNZpStfIfqyrEstnP2TIEE8n/fjvv/++p5Mlonr37u3pQrFPeU9kZWwAWLhwoZMXLVqELMgYEAD89Kc/dbJ+d0gy5DNcuXKlp7v11lud/Pjjj3u6uro6J+t4Tbdu3Zzct29fTydXytVxvFAJrKzf60quGsCRECGEkGjQCBFCCIlGbqWhs6YCSnTlWDl01Sm2svKxTnX84x//6GQ9HJZtkYvfAcDo0aNLnk8OlSuZvthUSVO1N6TTC71JZCr9sGHDPJ1Mh9XuuMMPP9zJOlV23LhxTn7iiSc8nUzr1+640DWsWrXKyXJGPeBXSdAVPpKiXclyu6lUh0/qPspaISJ0TD1tQLpQZfUN4IdufonsBzfffLOnk9U4Lr/8ck8np4/oBT5DlTOyLt6YN/yaEkIIiQaNECGEkGjQCBFCCIlGxcv2hHjkkUe87blz5zpZryop/bB/+MMfPJ1MnW3fvr2nO//88538k5/8xNPJtEgdJ2AcqLyEStck7Wvary1XnBw5cqSn0/HAUoTSX3U8Sq6CGtpXxzCnT5/u5CeffNLTydJDaVYzDqWrN/UyU1lXCc36OxkvBoCbbrrJyfo5hGIvsgSVnlqyZMkSJ+vq21deeaWTdb/ef//9nZwm7lrJGBG/rIQQQqJBI0QIISQamSsmpBm6Jk3f1lURPvvsMyevW7fO03344YdO1lVlpVtNpzOecsopTtbpknJRKS72VR7yducmdeNpt1rIvSp/F9pPptQCwEsvveRknSorF8CbOnWqp5PV4tevX+/pQm61pH00tKhdtZLHlJBd/S7pcfbZZx9v+6STTsrUFplqraeI3HfffU7WKwqsWbPGyTodXy7GGar6ktUVmQccCRFCCIkGjRAhhJBo0AgRQgiJRvSyPfJ3aaogd+zY0cnHH3+8p/vZz37mZF0FuV27dk5Os8oryYck91XvI8s3vf76655uwoQJTv7yyy893b777uvkUP/M6g/XFa9nz57t5Pnz53s6WULoz3/+s6eTK3PW1NR4OlleSKeAy7JBad6/pti384oDJUXeb33vs07nkGWfTjvtNE8npxvoyudyNYC1a9dmOnfMPsGRECGEkGjQCBFCCIlGZndc1uHbpk2bvG3pmtApr9u2bXOyrkYrh6t6eCrTcbds2eLppEsjNGyOmbK4OyLvr3bLyuoY2uUm0/rTVAkIuV5l/xkwYICn+9WvfuXkadOmeTpZvV338xUrVpRsp6zaffXVV3u6k08+2cl6moJM47399tuRlGpO0a5/f3XKfVJXel7vcahahSRNlQuJnnYi3bQtWrQoecw06fiybfpbmEcFk6RwJEQIISQaNEKEEEKiQSNECCEkGhVfVlGntU6ePNnJsoosAGzcuNHJtbW1nu6yyy5zsi6bMX78eCcfe+yxnk7Gkvr06ePpWrduHWw7aTj1PupQzE37nGV685lnnunpZBq2jqeE0miTriopU/oBoHv37iV1IeQKpsccc4ynu+uuu5ysY1DS/y/LSgF+nEDfs8GDBzv5xhtv9HRJK4g3RkrFcZNOA0lTLTrrMSVp4s6S1atXe9vPPvusk3Vpp6RlptKkkldy1QCOhAghhESDRogQQkg0Ku6O05VcBw0a5OSPPvrI00n32MCBAz2dnEG8YcMGTyeryk6aNMnTLVq0aKfnBoAjjzzSydpl0qFDB5CGU+86SOMWkem4OjU35AqRCxPqtNakx9DIfjFx4kRPJxcQe+655zydrN5+5513ejpZcTt0fXoRPbmtr0Ee84ADDiipqzZKVfHf2T6ltkvp9IKC8nugq1qHFjtMim6XnK7ywAMPeLp7773XyXraiQxVyGrtgO9WSzNNoZJwJEQIISQaNEKEEEKiQSNECCEkGhWPCenYikwf1aV5ZApq//79Sx5H+2elj/Trr7/2dDLVcebMmZ5OrkJ4ww03eDrpHw6Vh9GxB5lW21h9stVEGn9/KEU7K9LHrtOppd/+nnvuKXkMma69K2SZqc2bN3s6WV08r0rO1UKamGII+bu7777b0x144IFOvuCCCzydrNyfJsYmn6GuCD99+nQnP/PMM55OPk89leSaa65xsqy6DvwwrV/SWL45TbunEkIIadTQCBFCCIlGxd1xIS666CJvO+ROkdtyMSgA+OUvf+lknZ4qXXDvvPOOp1u2bJmTH374YU/XqVMnJ2v3n0w7Hz58uKc74ogjnKyH7aFZ+0l1TYXQ9aapjt3Q/dIQqr6dh3sIAD755BMnz5gxw9PddtttJdvSFPuIJOs7EfrdpZde6ulklfQpU6Z4ugsvvNDJo0aN8nTSJa/bJd1sOg17wYIFTj7ssMM8nawUol3+0m2Y1D0N+O9VKOW83N8fjoQIIYREg0aIEEJINGiECCGERCO3mFDSMhpZYx9p/JDSv6njTLIK8mOPPebp3njjDSc///zzni4Ulxg5cqSTddVumWKblabk36+/j6EUYn29W7dudfLy5cs93bx585wsV2CV5wIqv5pommcWWsVSlubRKdryvuj7Wc2rpyYhzf2V90K/x/JbcfHFF3s6uWqvnNoB+PEcHVuW5aJ0THrWrFlOXrlypaeT1c31d0tOO9Fp10lXVg3FMDWVnD7CkRAhhJBo0AgRQgiJRmZ3XNa0vTQphFmOr4+jfydTqDt27OjpRowY4WS5oJ4+pm6nnD0t3X0A0KpVq9RtBpqWC06SZCa/vhfr1q1z8uzZsz2dXBRRp+oPGTLEyT169EjVzkoi78natWs93fz58528cOFCTyfdMt26dfN0Q4cOdTIrwO8gTfXrc845x8m64r5Mp37hhRdKHkOnfY8ZM8bJ+h3v2bOnk/WqAfJZ55X+H6KS3x+OhAghhESDRogQQkg0aIQIIYREoyJle5Km++VVekT62EOxlsMPP9zTye28YjRJrz0UK2lK8aL6a0lzDXLfUCpy3759Pd15553nZO1jb6zoNGwZD1u/fr2nk/eiTZs2nq5Lly5OlinDTZVQzDbr+yJjilIG/NjysGHDPJ18LjJeDPjPKWtF+KzXkzUeX244EiKEEBINGiFCCCHRyOyOy+pO0TOWQ8cJzSQvR6WFpO3K6zhc1G4HSdPz0ywMWC33VF6DTrU+66yznKxn38uKH4sXL/Z0cmpAmkX0GjtJ3Llp3E5Z+0jXrl13KjeEPFKvY3/vssCRECGEkGjQCBFCCIkGjRAhhJBoVDxFO69U5JAfNKuPNK+yQUkpd1yrMVLqWpLGBnWlbFmGRcc+kpQIagyErr1z585OlmWlAKBfv35O1tXFBw8e7GS9ou/uRsz3J803LWY8J+Y0kOp4SwkhhDRJaIQIIYREoyLuuDwqbJfjfOU6f7WduzEQcoXKauennnqqp6urq3Py0qVLPV1Tu6farda7d28n9+rVy9NViysyLVncuTFprO3SMEWbEELIbgmNECGEkGjQCBFCCIlG06nnQaqC+nTrUIkdXdpJpmHr0jWhNGV9nKZGU03jJ7sXHAkRQgiJBo0QIYSQaNAdRypKfepwyFUWSi/Wacq1tbVOPv300z1d8+bNszSREFJBOBIihBASDRohQggh0aARIoQQEg2TZjU/Y8yXAD4tX3NIGTnYWtt517uVD/afqob9hzSEkv0nlREihBBC8oTuOEIIIdGgESKEEBINGiFCCCHRoBEihBASDRohQggh0aARIoQQEg0aIUIIIdGgESKEEBINGiFCCCHR+H+IvC2wOKdC0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "fig = plt.figure()\n",
    "for i in range(3):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8238cc9b",
   "metadata": {},
   "source": [
    "# Building Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e788ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionNNetwork, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(1024, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 34)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd17b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 32\n",
    "learning_rate = 0.001\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "model = ConvolutionNNetwork()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate);\n",
    "criterion = nn.CrossEntropyLoss();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa530951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/32], Step [100/2698], Loss: 3.1824, Accuracy: 21.88%\n",
      "Epoch [1/32], Step [200/2698], Loss: 1.9857, Accuracy: 40.62%\n",
      "Epoch [1/32], Step [300/2698], Loss: 1.8519, Accuracy: 62.50%\n",
      "Epoch [1/32], Step [400/2698], Loss: 1.7755, Accuracy: 53.12%\n",
      "Epoch [1/32], Step [500/2698], Loss: 1.5764, Accuracy: 62.50%\n",
      "Epoch [1/32], Step [600/2698], Loss: 1.1815, Accuracy: 71.88%\n",
      "Epoch [1/32], Step [700/2698], Loss: 1.3320, Accuracy: 71.88%\n",
      "Epoch [1/32], Step [800/2698], Loss: 1.4333, Accuracy: 62.50%\n",
      "Epoch [1/32], Step [900/2698], Loss: 0.8954, Accuracy: 78.12%\n",
      "Epoch [1/32], Step [1000/2698], Loss: 0.9100, Accuracy: 87.50%\n",
      "Epoch [1/32], Step [1100/2698], Loss: 1.3246, Accuracy: 71.88%\n",
      "Epoch [1/32], Step [1200/2698], Loss: 1.8798, Accuracy: 65.62%\n",
      "Epoch [1/32], Step [1300/2698], Loss: 1.2701, Accuracy: 68.75%\n",
      "Epoch [1/32], Step [1400/2698], Loss: 1.2323, Accuracy: 75.00%\n",
      "Epoch [1/32], Step [1500/2698], Loss: 1.2516, Accuracy: 62.50%\n",
      "Epoch [1/32], Step [1600/2698], Loss: 1.7409, Accuracy: 59.38%\n",
      "Epoch [1/32], Step [1700/2698], Loss: 1.4330, Accuracy: 62.50%\n",
      "Epoch [1/32], Step [1800/2698], Loss: 0.7232, Accuracy: 75.00%\n",
      "Epoch [1/32], Step [1900/2698], Loss: 1.1362, Accuracy: 71.88%\n",
      "Epoch [1/32], Step [2000/2698], Loss: 1.1415, Accuracy: 68.75%\n",
      "Epoch [1/32], Step [2100/2698], Loss: 1.0256, Accuracy: 81.25%\n",
      "Epoch [1/32], Step [2200/2698], Loss: 1.3762, Accuracy: 65.62%\n",
      "Epoch [1/32], Step [2300/2698], Loss: 1.0768, Accuracy: 71.88%\n",
      "Epoch [1/32], Step [2400/2698], Loss: 0.9259, Accuracy: 75.00%\n",
      "Epoch [1/32], Step [2500/2698], Loss: 1.0073, Accuracy: 75.00%\n",
      "Epoch [1/32], Step [2600/2698], Loss: 1.2725, Accuracy: 71.88%\n",
      "Epoch [2/32], Step [100/2698], Loss: 1.6824, Accuracy: 71.88%\n",
      "Epoch [2/32], Step [200/2698], Loss: 1.6262, Accuracy: 68.75%\n",
      "Epoch [2/32], Step [300/2698], Loss: 1.3787, Accuracy: 75.00%\n",
      "Epoch [2/32], Step [400/2698], Loss: 1.1078, Accuracy: 75.00%\n",
      "Epoch [2/32], Step [500/2698], Loss: 1.1724, Accuracy: 68.75%\n",
      "Epoch [2/32], Step [600/2698], Loss: 1.1680, Accuracy: 68.75%\n",
      "Epoch [2/32], Step [700/2698], Loss: 0.8673, Accuracy: 84.38%\n",
      "Epoch [2/32], Step [800/2698], Loss: 0.7134, Accuracy: 75.00%\n",
      "Epoch [2/32], Step [900/2698], Loss: 1.6992, Accuracy: 65.62%\n",
      "Epoch [2/32], Step [1000/2698], Loss: 1.2045, Accuracy: 78.12%\n",
      "Epoch [2/32], Step [1100/2698], Loss: 0.9660, Accuracy: 84.38%\n",
      "Epoch [2/32], Step [1200/2698], Loss: 1.3514, Accuracy: 78.12%\n",
      "Epoch [2/32], Step [1300/2698], Loss: 1.4856, Accuracy: 78.12%\n",
      "Epoch [2/32], Step [1400/2698], Loss: 1.2170, Accuracy: 78.12%\n",
      "Epoch [2/32], Step [1500/2698], Loss: 1.0882, Accuracy: 75.00%\n",
      "Epoch [2/32], Step [1600/2698], Loss: 1.3284, Accuracy: 78.12%\n",
      "Epoch [2/32], Step [1700/2698], Loss: 1.1340, Accuracy: 81.25%\n",
      "Epoch [2/32], Step [1800/2698], Loss: 0.8698, Accuracy: 78.12%\n",
      "Epoch [2/32], Step [1900/2698], Loss: 0.9619, Accuracy: 81.25%\n",
      "Epoch [2/32], Step [2000/2698], Loss: 0.9186, Accuracy: 78.12%\n",
      "Epoch [2/32], Step [2100/2698], Loss: 0.7942, Accuracy: 84.38%\n",
      "Epoch [2/32], Step [2200/2698], Loss: 0.7338, Accuracy: 81.25%\n",
      "Epoch [2/32], Step [2300/2698], Loss: 1.0706, Accuracy: 84.38%\n",
      "Epoch [2/32], Step [2400/2698], Loss: 1.0704, Accuracy: 71.88%\n",
      "Epoch [2/32], Step [2500/2698], Loss: 2.1343, Accuracy: 59.38%\n",
      "Epoch [2/32], Step [2600/2698], Loss: 0.7602, Accuracy: 87.50%\n",
      "Epoch [3/32], Step [100/2698], Loss: 0.8893, Accuracy: 84.38%\n",
      "Epoch [3/32], Step [200/2698], Loss: 0.9120, Accuracy: 78.12%\n",
      "Epoch [3/32], Step [300/2698], Loss: 0.7521, Accuracy: 87.50%\n",
      "Epoch [3/32], Step [400/2698], Loss: 1.5606, Accuracy: 59.38%\n",
      "Epoch [3/32], Step [500/2698], Loss: 1.4598, Accuracy: 65.62%\n",
      "Epoch [3/32], Step [600/2698], Loss: 0.7417, Accuracy: 84.38%\n",
      "Epoch [3/32], Step [700/2698], Loss: 1.6063, Accuracy: 71.88%\n",
      "Epoch [3/32], Step [800/2698], Loss: 0.7293, Accuracy: 81.25%\n",
      "Epoch [3/32], Step [900/2698], Loss: 0.6789, Accuracy: 90.62%\n",
      "Epoch [3/32], Step [1000/2698], Loss: 0.6966, Accuracy: 81.25%\n",
      "Epoch [3/32], Step [1100/2698], Loss: 0.9718, Accuracy: 71.88%\n",
      "Epoch [3/32], Step [1200/2698], Loss: 1.1078, Accuracy: 81.25%\n",
      "Epoch [3/32], Step [1300/2698], Loss: 0.9758, Accuracy: 84.38%\n",
      "Epoch [3/32], Step [1400/2698], Loss: 0.7592, Accuracy: 84.38%\n",
      "Epoch [3/32], Step [1500/2698], Loss: 0.9621, Accuracy: 71.88%\n",
      "Epoch [3/32], Step [1600/2698], Loss: 1.2847, Accuracy: 84.38%\n",
      "Epoch [3/32], Step [1700/2698], Loss: 0.8576, Accuracy: 78.12%\n",
      "Epoch [3/32], Step [1800/2698], Loss: 0.8843, Accuracy: 81.25%\n",
      "Epoch [3/32], Step [1900/2698], Loss: 1.1320, Accuracy: 78.12%\n",
      "Epoch [3/32], Step [2000/2698], Loss: 0.6911, Accuracy: 87.50%\n",
      "Epoch [3/32], Step [2100/2698], Loss: 1.2255, Accuracy: 81.25%\n",
      "Epoch [3/32], Step [2200/2698], Loss: 1.0616, Accuracy: 78.12%\n",
      "Epoch [3/32], Step [2300/2698], Loss: 1.3203, Accuracy: 71.88%\n",
      "Epoch [3/32], Step [2400/2698], Loss: 1.3863, Accuracy: 78.12%\n",
      "Epoch [3/32], Step [2500/2698], Loss: 0.9128, Accuracy: 78.12%\n",
      "Epoch [3/32], Step [2600/2698], Loss: 1.4251, Accuracy: 75.00%\n",
      "Epoch [4/32], Step [100/2698], Loss: 0.3924, Accuracy: 90.62%\n",
      "Epoch [4/32], Step [200/2698], Loss: 0.4329, Accuracy: 93.75%\n",
      "Epoch [4/32], Step [300/2698], Loss: 0.8252, Accuracy: 84.38%\n",
      "Epoch [4/32], Step [400/2698], Loss: 0.8917, Accuracy: 84.38%\n",
      "Epoch [4/32], Step [500/2698], Loss: 0.5876, Accuracy: 84.38%\n",
      "Epoch [4/32], Step [600/2698], Loss: 2.4312, Accuracy: 62.50%\n",
      "Epoch [4/32], Step [700/2698], Loss: 0.8319, Accuracy: 87.50%\n",
      "Epoch [4/32], Step [800/2698], Loss: 0.6559, Accuracy: 84.38%\n",
      "Epoch [4/32], Step [900/2698], Loss: 0.3451, Accuracy: 93.75%\n",
      "Epoch [4/32], Step [1000/2698], Loss: 0.6629, Accuracy: 87.50%\n",
      "Epoch [4/32], Step [1100/2698], Loss: 0.8900, Accuracy: 84.38%\n",
      "Epoch [4/32], Step [1200/2698], Loss: 1.5107, Accuracy: 68.75%\n",
      "Epoch [4/32], Step [1300/2698], Loss: 0.4414, Accuracy: 90.62%\n",
      "Epoch [4/32], Step [1400/2698], Loss: 0.8299, Accuracy: 81.25%\n",
      "Epoch [4/32], Step [1500/2698], Loss: 0.9603, Accuracy: 81.25%\n",
      "Epoch [4/32], Step [1600/2698], Loss: 0.8934, Accuracy: 81.25%\n",
      "Epoch [4/32], Step [1700/2698], Loss: 0.3917, Accuracy: 93.75%\n",
      "Epoch [4/32], Step [1800/2698], Loss: 1.0990, Accuracy: 81.25%\n",
      "Epoch [4/32], Step [1900/2698], Loss: 1.3099, Accuracy: 75.00%\n",
      "Epoch [4/32], Step [2000/2698], Loss: 0.3740, Accuracy: 90.62%\n",
      "Epoch [4/32], Step [2100/2698], Loss: 1.2644, Accuracy: 81.25%\n",
      "Epoch [4/32], Step [2200/2698], Loss: 1.1538, Accuracy: 78.12%\n",
      "Epoch [4/32], Step [2300/2698], Loss: 0.8543, Accuracy: 81.25%\n",
      "Epoch [4/32], Step [2400/2698], Loss: 2.0001, Accuracy: 53.12%\n",
      "Epoch [4/32], Step [2500/2698], Loss: 1.1035, Accuracy: 78.12%\n",
      "Epoch [4/32], Step [2600/2698], Loss: 0.7338, Accuracy: 90.62%\n",
      "Epoch [5/32], Step [100/2698], Loss: 0.7824, Accuracy: 84.38%\n",
      "Epoch [5/32], Step [200/2698], Loss: 0.7137, Accuracy: 81.25%\n",
      "Epoch [5/32], Step [300/2698], Loss: 0.7098, Accuracy: 84.38%\n",
      "Epoch [5/32], Step [400/2698], Loss: 1.3708, Accuracy: 75.00%\n",
      "Epoch [5/32], Step [500/2698], Loss: 0.7587, Accuracy: 90.62%\n",
      "Epoch [5/32], Step [600/2698], Loss: 1.2522, Accuracy: 78.12%\n",
      "Epoch [5/32], Step [700/2698], Loss: 1.3527, Accuracy: 81.25%\n",
      "Epoch [5/32], Step [800/2698], Loss: 0.9335, Accuracy: 81.25%\n",
      "Epoch [5/32], Step [900/2698], Loss: 0.8072, Accuracy: 84.38%\n",
      "Epoch [5/32], Step [1000/2698], Loss: 0.6858, Accuracy: 81.25%\n",
      "Epoch [5/32], Step [1100/2698], Loss: 0.8788, Accuracy: 81.25%\n",
      "Epoch [5/32], Step [1200/2698], Loss: 1.1118, Accuracy: 75.00%\n",
      "Epoch [5/32], Step [1300/2698], Loss: 1.4247, Accuracy: 78.12%\n",
      "Epoch [5/32], Step [1400/2698], Loss: 0.9774, Accuracy: 75.00%\n",
      "Epoch [5/32], Step [1500/2698], Loss: 0.5050, Accuracy: 90.62%\n",
      "Epoch [5/32], Step [1600/2698], Loss: 1.1561, Accuracy: 68.75%\n",
      "Epoch [5/32], Step [1700/2698], Loss: 1.0924, Accuracy: 68.75%\n",
      "Epoch [5/32], Step [1800/2698], Loss: 1.7172, Accuracy: 84.38%\n",
      "Epoch [5/32], Step [1900/2698], Loss: 0.6729, Accuracy: 81.25%\n",
      "Epoch [5/32], Step [2000/2698], Loss: 0.5259, Accuracy: 87.50%\n",
      "Epoch [5/32], Step [2100/2698], Loss: 0.8832, Accuracy: 84.38%\n",
      "Epoch [5/32], Step [2200/2698], Loss: 1.6039, Accuracy: 75.00%\n",
      "Epoch [5/32], Step [2300/2698], Loss: 0.5048, Accuracy: 90.62%\n",
      "Epoch [5/32], Step [2400/2698], Loss: 0.7626, Accuracy: 84.38%\n",
      "Epoch [5/32], Step [2500/2698], Loss: 0.9374, Accuracy: 87.50%\n",
      "Epoch [5/32], Step [2600/2698], Loss: 0.6056, Accuracy: 87.50%\n",
      "Epoch [6/32], Step [100/2698], Loss: 0.9842, Accuracy: 78.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/32], Step [200/2698], Loss: 1.2551, Accuracy: 78.12%\n",
      "Epoch [6/32], Step [300/2698], Loss: 0.6553, Accuracy: 87.50%\n",
      "Epoch [6/32], Step [400/2698], Loss: 0.8999, Accuracy: 81.25%\n",
      "Epoch [6/32], Step [500/2698], Loss: 0.8079, Accuracy: 87.50%\n",
      "Epoch [6/32], Step [600/2698], Loss: 1.0445, Accuracy: 81.25%\n",
      "Epoch [6/32], Step [700/2698], Loss: 1.0809, Accuracy: 78.12%\n",
      "Epoch [6/32], Step [800/2698], Loss: 0.9063, Accuracy: 84.38%\n",
      "Epoch [6/32], Step [900/2698], Loss: 0.9109, Accuracy: 84.38%\n",
      "Epoch [6/32], Step [1000/2698], Loss: 0.8165, Accuracy: 84.38%\n",
      "Epoch [6/32], Step [1100/2698], Loss: 0.3215, Accuracy: 93.75%\n",
      "Epoch [6/32], Step [1200/2698], Loss: 0.9202, Accuracy: 81.25%\n",
      "Epoch [6/32], Step [1300/2698], Loss: 1.6560, Accuracy: 62.50%\n",
      "Epoch [6/32], Step [1400/2698], Loss: 0.6908, Accuracy: 90.62%\n",
      "Epoch [6/32], Step [1500/2698], Loss: 1.1723, Accuracy: 78.12%\n",
      "Epoch [6/32], Step [1600/2698], Loss: 1.3593, Accuracy: 71.88%\n",
      "Epoch [6/32], Step [1700/2698], Loss: 1.1548, Accuracy: 84.38%\n",
      "Epoch [6/32], Step [1800/2698], Loss: 1.2815, Accuracy: 81.25%\n",
      "Epoch [6/32], Step [1900/2698], Loss: 1.4095, Accuracy: 84.38%\n",
      "Epoch [6/32], Step [2000/2698], Loss: 0.8269, Accuracy: 78.12%\n",
      "Epoch [6/32], Step [2100/2698], Loss: 1.1431, Accuracy: 78.12%\n",
      "Epoch [6/32], Step [2200/2698], Loss: 1.2427, Accuracy: 71.88%\n",
      "Epoch [6/32], Step [2300/2698], Loss: 1.1835, Accuracy: 84.38%\n",
      "Epoch [6/32], Step [2400/2698], Loss: 0.8042, Accuracy: 87.50%\n",
      "Epoch [6/32], Step [2500/2698], Loss: 0.6109, Accuracy: 84.38%\n",
      "Epoch [6/32], Step [2600/2698], Loss: 1.4190, Accuracy: 81.25%\n",
      "Epoch [7/32], Step [100/2698], Loss: 0.8497, Accuracy: 84.38%\n",
      "Epoch [7/32], Step [200/2698], Loss: 0.9715, Accuracy: 78.12%\n",
      "Epoch [7/32], Step [300/2698], Loss: 0.8665, Accuracy: 87.50%\n",
      "Epoch [7/32], Step [400/2698], Loss: 0.6544, Accuracy: 87.50%\n",
      "Epoch [7/32], Step [500/2698], Loss: 1.1631, Accuracy: 81.25%\n",
      "Epoch [7/32], Step [600/2698], Loss: 0.8766, Accuracy: 75.00%\n",
      "Epoch [7/32], Step [700/2698], Loss: 1.0526, Accuracy: 81.25%\n",
      "Epoch [7/32], Step [800/2698], Loss: 0.5352, Accuracy: 93.75%\n",
      "Epoch [7/32], Step [900/2698], Loss: 1.0202, Accuracy: 78.12%\n",
      "Epoch [7/32], Step [1000/2698], Loss: 0.8517, Accuracy: 81.25%\n",
      "Epoch [7/32], Step [1100/2698], Loss: 0.8226, Accuracy: 84.38%\n",
      "Epoch [7/32], Step [1200/2698], Loss: 1.0591, Accuracy: 78.12%\n",
      "Epoch [7/32], Step [1300/2698], Loss: 0.3815, Accuracy: 93.75%\n",
      "Epoch [7/32], Step [1400/2698], Loss: 1.3156, Accuracy: 78.12%\n",
      "Epoch [7/32], Step [1500/2698], Loss: 1.0580, Accuracy: 65.62%\n",
      "Epoch [7/32], Step [1600/2698], Loss: 0.4832, Accuracy: 87.50%\n",
      "Epoch [7/32], Step [1700/2698], Loss: 1.4635, Accuracy: 68.75%\n",
      "Epoch [7/32], Step [1800/2698], Loss: 1.0189, Accuracy: 84.38%\n",
      "Epoch [7/32], Step [1900/2698], Loss: 1.5953, Accuracy: 56.25%\n",
      "Epoch [7/32], Step [2000/2698], Loss: 1.0652, Accuracy: 78.12%\n",
      "Epoch [7/32], Step [2100/2698], Loss: 0.8155, Accuracy: 81.25%\n",
      "Epoch [7/32], Step [2200/2698], Loss: 0.8347, Accuracy: 78.12%\n",
      "Epoch [7/32], Step [2300/2698], Loss: 0.7394, Accuracy: 81.25%\n",
      "Epoch [7/32], Step [2400/2698], Loss: 0.9533, Accuracy: 78.12%\n",
      "Epoch [7/32], Step [2500/2698], Loss: 0.8918, Accuracy: 71.88%\n",
      "Epoch [7/32], Step [2600/2698], Loss: 1.9773, Accuracy: 65.62%\n",
      "Epoch [8/32], Step [100/2698], Loss: 1.1328, Accuracy: 71.88%\n",
      "Epoch [8/32], Step [200/2698], Loss: 1.4019, Accuracy: 81.25%\n",
      "Epoch [8/32], Step [300/2698], Loss: 1.0548, Accuracy: 81.25%\n",
      "Epoch [8/32], Step [400/2698], Loss: 1.1263, Accuracy: 71.88%\n",
      "Epoch [8/32], Step [500/2698], Loss: 0.3668, Accuracy: 90.62%\n",
      "Epoch [8/32], Step [600/2698], Loss: 0.9147, Accuracy: 78.12%\n",
      "Epoch [8/32], Step [700/2698], Loss: 1.1343, Accuracy: 75.00%\n",
      "Epoch [8/32], Step [800/2698], Loss: 0.8921, Accuracy: 87.50%\n",
      "Epoch [8/32], Step [900/2698], Loss: 0.8674, Accuracy: 75.00%\n",
      "Epoch [8/32], Step [1000/2698], Loss: 0.6801, Accuracy: 84.38%\n",
      "Epoch [8/32], Step [1100/2698], Loss: 0.7637, Accuracy: 84.38%\n",
      "Epoch [8/32], Step [1200/2698], Loss: 0.5133, Accuracy: 93.75%\n",
      "Epoch [8/32], Step [1300/2698], Loss: 0.6476, Accuracy: 90.62%\n",
      "Epoch [8/32], Step [1400/2698], Loss: 1.0064, Accuracy: 84.38%\n",
      "Epoch [8/32], Step [1500/2698], Loss: 0.6408, Accuracy: 90.62%\n",
      "Epoch [8/32], Step [1600/2698], Loss: 1.1678, Accuracy: 81.25%\n",
      "Epoch [8/32], Step [1700/2698], Loss: 0.6827, Accuracy: 84.38%\n",
      "Epoch [8/32], Step [1800/2698], Loss: 0.8794, Accuracy: 84.38%\n",
      "Epoch [8/32], Step [1900/2698], Loss: 0.7696, Accuracy: 87.50%\n",
      "Epoch [8/32], Step [2000/2698], Loss: 0.9641, Accuracy: 78.12%\n",
      "Epoch [8/32], Step [2100/2698], Loss: 1.8673, Accuracy: 65.62%\n",
      "Epoch [8/32], Step [2200/2698], Loss: 1.2042, Accuracy: 78.12%\n",
      "Epoch [8/32], Step [2300/2698], Loss: 0.5581, Accuracy: 84.38%\n",
      "Epoch [8/32], Step [2400/2698], Loss: 1.7679, Accuracy: 65.62%\n",
      "Epoch [8/32], Step [2500/2698], Loss: 1.1065, Accuracy: 75.00%\n",
      "Epoch [8/32], Step [2600/2698], Loss: 1.0788, Accuracy: 81.25%\n",
      "Epoch [9/32], Step [100/2698], Loss: 1.1876, Accuracy: 78.12%\n",
      "Epoch [9/32], Step [200/2698], Loss: 0.5862, Accuracy: 87.50%\n",
      "Epoch [9/32], Step [300/2698], Loss: 1.1110, Accuracy: 81.25%\n",
      "Epoch [9/32], Step [400/2698], Loss: 0.6714, Accuracy: 84.38%\n",
      "Epoch [9/32], Step [500/2698], Loss: 0.6601, Accuracy: 84.38%\n",
      "Epoch [9/32], Step [600/2698], Loss: 1.1534, Accuracy: 81.25%\n",
      "Epoch [9/32], Step [700/2698], Loss: 1.1020, Accuracy: 84.38%\n",
      "Epoch [9/32], Step [800/2698], Loss: 0.4441, Accuracy: 93.75%\n",
      "Epoch [9/32], Step [900/2698], Loss: 1.0122, Accuracy: 84.38%\n",
      "Epoch [9/32], Step [1000/2698], Loss: 0.7636, Accuracy: 84.38%\n",
      "Epoch [9/32], Step [1100/2698], Loss: 0.4122, Accuracy: 90.62%\n",
      "Epoch [9/32], Step [1200/2698], Loss: 0.6323, Accuracy: 90.62%\n",
      "Epoch [9/32], Step [1300/2698], Loss: 0.7861, Accuracy: 81.25%\n",
      "Epoch [9/32], Step [1400/2698], Loss: 0.9745, Accuracy: 75.00%\n",
      "Epoch [9/32], Step [1500/2698], Loss: 0.8105, Accuracy: 81.25%\n",
      "Epoch [9/32], Step [1600/2698], Loss: 1.2308, Accuracy: 75.00%\n",
      "Epoch [9/32], Step [1700/2698], Loss: 0.8839, Accuracy: 84.38%\n",
      "Epoch [9/32], Step [1800/2698], Loss: 1.3390, Accuracy: 75.00%\n",
      "Epoch [9/32], Step [1900/2698], Loss: 0.3470, Accuracy: 90.62%\n",
      "Epoch [9/32], Step [2000/2698], Loss: 0.9121, Accuracy: 84.38%\n",
      "Epoch [9/32], Step [2100/2698], Loss: 1.1129, Accuracy: 84.38%\n",
      "Epoch [9/32], Step [2200/2698], Loss: 0.9465, Accuracy: 81.25%\n",
      "Epoch [9/32], Step [2300/2698], Loss: 0.6600, Accuracy: 71.88%\n",
      "Epoch [9/32], Step [2400/2698], Loss: 0.8899, Accuracy: 75.00%\n",
      "Epoch [9/32], Step [2500/2698], Loss: 0.9566, Accuracy: 78.12%\n",
      "Epoch [9/32], Step [2600/2698], Loss: 1.0311, Accuracy: 78.12%\n",
      "Epoch [10/32], Step [100/2698], Loss: 1.2992, Accuracy: 71.88%\n",
      "Epoch [10/32], Step [200/2698], Loss: 0.6721, Accuracy: 90.62%\n",
      "Epoch [10/32], Step [300/2698], Loss: 0.6503, Accuracy: 90.62%\n",
      "Epoch [10/32], Step [400/2698], Loss: 0.8034, Accuracy: 81.25%\n",
      "Epoch [10/32], Step [500/2698], Loss: 0.6599, Accuracy: 90.62%\n",
      "Epoch [10/32], Step [600/2698], Loss: 0.7529, Accuracy: 81.25%\n",
      "Epoch [10/32], Step [700/2698], Loss: 1.2723, Accuracy: 81.25%\n",
      "Epoch [10/32], Step [800/2698], Loss: 1.1225, Accuracy: 78.12%\n",
      "Epoch [10/32], Step [900/2698], Loss: 1.0106, Accuracy: 78.12%\n",
      "Epoch [10/32], Step [1000/2698], Loss: 0.7945, Accuracy: 84.38%\n",
      "Epoch [10/32], Step [1100/2698], Loss: 0.9093, Accuracy: 78.12%\n",
      "Epoch [10/32], Step [1200/2698], Loss: 0.6595, Accuracy: 87.50%\n",
      "Epoch [10/32], Step [1300/2698], Loss: 0.8602, Accuracy: 84.38%\n",
      "Epoch [10/32], Step [1400/2698], Loss: 1.1061, Accuracy: 78.12%\n",
      "Epoch [10/32], Step [1500/2698], Loss: 0.5973, Accuracy: 87.50%\n",
      "Epoch [10/32], Step [1600/2698], Loss: 1.4962, Accuracy: 71.88%\n",
      "Epoch [10/32], Step [1700/2698], Loss: 0.6950, Accuracy: 84.38%\n",
      "Epoch [10/32], Step [1800/2698], Loss: 1.0226, Accuracy: 75.00%\n",
      "Epoch [10/32], Step [1900/2698], Loss: 0.8873, Accuracy: 84.38%\n",
      "Epoch [10/32], Step [2000/2698], Loss: 0.5910, Accuracy: 87.50%\n",
      "Epoch [10/32], Step [2100/2698], Loss: 0.7775, Accuracy: 75.00%\n",
      "Epoch [10/32], Step [2200/2698], Loss: 0.7697, Accuracy: 78.12%\n",
      "Epoch [10/32], Step [2300/2698], Loss: 0.5248, Accuracy: 87.50%\n",
      "Epoch [10/32], Step [2400/2698], Loss: 1.5855, Accuracy: 75.00%\n",
      "Epoch [10/32], Step [2500/2698], Loss: 0.7129, Accuracy: 84.38%\n",
      "Epoch [10/32], Step [2600/2698], Loss: 0.9251, Accuracy: 84.38%\n",
      "Epoch [11/32], Step [100/2698], Loss: 1.5268, Accuracy: 68.75%\n",
      "Epoch [11/32], Step [200/2698], Loss: 0.7340, Accuracy: 84.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/32], Step [300/2698], Loss: 0.7266, Accuracy: 81.25%\n",
      "Epoch [11/32], Step [400/2698], Loss: 0.6872, Accuracy: 87.50%\n",
      "Epoch [11/32], Step [500/2698], Loss: 0.8258, Accuracy: 87.50%\n",
      "Epoch [11/32], Step [600/2698], Loss: 1.0286, Accuracy: 78.12%\n",
      "Epoch [11/32], Step [700/2698], Loss: 0.7952, Accuracy: 81.25%\n",
      "Epoch [11/32], Step [800/2698], Loss: 0.5997, Accuracy: 90.62%\n",
      "Epoch [11/32], Step [900/2698], Loss: 0.6826, Accuracy: 90.62%\n",
      "Epoch [11/32], Step [1000/2698], Loss: 0.3246, Accuracy: 93.75%\n",
      "Epoch [11/32], Step [1100/2698], Loss: 0.6877, Accuracy: 84.38%\n",
      "Epoch [11/32], Step [1200/2698], Loss: 0.8990, Accuracy: 84.38%\n",
      "Epoch [11/32], Step [1300/2698], Loss: 0.5885, Accuracy: 84.38%\n",
      "Epoch [11/32], Step [1400/2698], Loss: 1.1502, Accuracy: 75.00%\n",
      "Epoch [11/32], Step [1500/2698], Loss: 1.5273, Accuracy: 78.12%\n",
      "Epoch [11/32], Step [1600/2698], Loss: 0.5149, Accuracy: 87.50%\n",
      "Epoch [11/32], Step [1700/2698], Loss: 0.4076, Accuracy: 96.88%\n",
      "Epoch [11/32], Step [1800/2698], Loss: 1.0148, Accuracy: 75.00%\n",
      "Epoch [11/32], Step [1900/2698], Loss: 1.0942, Accuracy: 75.00%\n",
      "Epoch [11/32], Step [2000/2698], Loss: 1.3474, Accuracy: 65.62%\n",
      "Epoch [11/32], Step [2100/2698], Loss: 0.9940, Accuracy: 81.25%\n",
      "Epoch [11/32], Step [2200/2698], Loss: 1.0665, Accuracy: 84.38%\n",
      "Epoch [11/32], Step [2300/2698], Loss: 1.0985, Accuracy: 71.88%\n",
      "Epoch [11/32], Step [2400/2698], Loss: 1.5799, Accuracy: 78.12%\n",
      "Epoch [11/32], Step [2500/2698], Loss: 0.6474, Accuracy: 90.62%\n",
      "Epoch [11/32], Step [2600/2698], Loss: 0.7734, Accuracy: 87.50%\n",
      "Epoch [12/32], Step [100/2698], Loss: 0.9420, Accuracy: 78.12%\n",
      "Epoch [12/32], Step [200/2698], Loss: 0.7438, Accuracy: 84.38%\n",
      "Epoch [12/32], Step [300/2698], Loss: 0.6544, Accuracy: 87.50%\n",
      "Epoch [12/32], Step [400/2698], Loss: 0.4456, Accuracy: 96.88%\n",
      "Epoch [12/32], Step [500/2698], Loss: 0.5691, Accuracy: 87.50%\n",
      "Epoch [12/32], Step [600/2698], Loss: 0.5826, Accuracy: 93.75%\n",
      "Epoch [12/32], Step [700/2698], Loss: 0.8439, Accuracy: 84.38%\n",
      "Epoch [12/32], Step [800/2698], Loss: 0.8358, Accuracy: 87.50%\n",
      "Epoch [12/32], Step [900/2698], Loss: 0.4835, Accuracy: 87.50%\n",
      "Epoch [12/32], Step [1000/2698], Loss: 1.1732, Accuracy: 75.00%\n",
      "Epoch [12/32], Step [1100/2698], Loss: 0.9679, Accuracy: 81.25%\n",
      "Epoch [12/32], Step [1200/2698], Loss: 1.0810, Accuracy: 71.88%\n",
      "Epoch [12/32], Step [1300/2698], Loss: 1.1318, Accuracy: 81.25%\n",
      "Epoch [12/32], Step [1400/2698], Loss: 0.8761, Accuracy: 84.38%\n",
      "Epoch [12/32], Step [1500/2698], Loss: 1.2912, Accuracy: 75.00%\n",
      "Epoch [12/32], Step [1600/2698], Loss: 1.4170, Accuracy: 71.88%\n",
      "Epoch [12/32], Step [1700/2698], Loss: 0.3633, Accuracy: 93.75%\n",
      "Epoch [12/32], Step [1800/2698], Loss: 0.6832, Accuracy: 81.25%\n",
      "Epoch [12/32], Step [1900/2698], Loss: 0.5306, Accuracy: 96.88%\n",
      "Epoch [12/32], Step [2000/2698], Loss: 0.5967, Accuracy: 87.50%\n",
      "Epoch [12/32], Step [2100/2698], Loss: 1.2150, Accuracy: 75.00%\n",
      "Epoch [12/32], Step [2200/2698], Loss: 0.6335, Accuracy: 81.25%\n",
      "Epoch [12/32], Step [2300/2698], Loss: 1.8452, Accuracy: 75.00%\n",
      "Epoch [12/32], Step [2400/2698], Loss: 1.5490, Accuracy: 68.75%\n",
      "Epoch [12/32], Step [2500/2698], Loss: 0.7961, Accuracy: 87.50%\n",
      "Epoch [12/32], Step [2600/2698], Loss: 0.8534, Accuracy: 84.38%\n",
      "Epoch [13/32], Step [100/2698], Loss: 1.4221, Accuracy: 71.88%\n",
      "Epoch [13/32], Step [200/2698], Loss: 0.6426, Accuracy: 90.62%\n",
      "Epoch [13/32], Step [300/2698], Loss: 1.1379, Accuracy: 78.12%\n",
      "Epoch [13/32], Step [400/2698], Loss: 0.5501, Accuracy: 90.62%\n",
      "Epoch [13/32], Step [500/2698], Loss: 0.7131, Accuracy: 87.50%\n",
      "Epoch [13/32], Step [600/2698], Loss: 0.8898, Accuracy: 84.38%\n",
      "Epoch [13/32], Step [700/2698], Loss: 1.5179, Accuracy: 71.88%\n",
      "Epoch [13/32], Step [800/2698], Loss: 0.6430, Accuracy: 84.38%\n",
      "Epoch [13/32], Step [900/2698], Loss: 1.5807, Accuracy: 75.00%\n",
      "Epoch [13/32], Step [1000/2698], Loss: 0.7686, Accuracy: 84.38%\n",
      "Epoch [13/32], Step [1100/2698], Loss: 0.8966, Accuracy: 87.50%\n",
      "Epoch [13/32], Step [1200/2698], Loss: 1.0637, Accuracy: 78.12%\n",
      "Epoch [13/32], Step [1300/2698], Loss: 0.6520, Accuracy: 87.50%\n",
      "Epoch [13/32], Step [1400/2698], Loss: 0.6645, Accuracy: 84.38%\n",
      "Epoch [13/32], Step [1500/2698], Loss: 0.9709, Accuracy: 75.00%\n",
      "Epoch [13/32], Step [1600/2698], Loss: 0.7912, Accuracy: 75.00%\n",
      "Epoch [13/32], Step [1700/2698], Loss: 0.6882, Accuracy: 87.50%\n",
      "Epoch [13/32], Step [1800/2698], Loss: 0.7481, Accuracy: 84.38%\n",
      "Epoch [13/32], Step [1900/2698], Loss: 1.1472, Accuracy: 75.00%\n",
      "Epoch [13/32], Step [2000/2698], Loss: 0.4377, Accuracy: 87.50%\n",
      "Epoch [13/32], Step [2100/2698], Loss: 1.0571, Accuracy: 68.75%\n",
      "Epoch [13/32], Step [2200/2698], Loss: 1.2904, Accuracy: 78.12%\n",
      "Epoch [13/32], Step [2300/2698], Loss: 0.4533, Accuracy: 93.75%\n",
      "Epoch [13/32], Step [2400/2698], Loss: 0.6608, Accuracy: 90.62%\n",
      "Epoch [13/32], Step [2500/2698], Loss: 0.4167, Accuracy: 90.62%\n",
      "Epoch [13/32], Step [2600/2698], Loss: 1.0456, Accuracy: 84.38%\n",
      "Epoch [14/32], Step [100/2698], Loss: 0.4814, Accuracy: 90.62%\n",
      "Epoch [14/32], Step [200/2698], Loss: 1.4570, Accuracy: 71.88%\n",
      "Epoch [14/32], Step [300/2698], Loss: 0.5518, Accuracy: 93.75%\n",
      "Epoch [14/32], Step [400/2698], Loss: 0.9586, Accuracy: 75.00%\n",
      "Epoch [14/32], Step [500/2698], Loss: 0.8825, Accuracy: 78.12%\n",
      "Epoch [14/32], Step [600/2698], Loss: 1.1273, Accuracy: 81.25%\n",
      "Epoch [14/32], Step [700/2698], Loss: 0.6490, Accuracy: 87.50%\n",
      "Epoch [14/32], Step [800/2698], Loss: 0.9922, Accuracy: 81.25%\n",
      "Epoch [14/32], Step [900/2698], Loss: 1.3733, Accuracy: 65.62%\n",
      "Epoch [14/32], Step [1000/2698], Loss: 1.1435, Accuracy: 75.00%\n",
      "Epoch [14/32], Step [1100/2698], Loss: 0.6714, Accuracy: 87.50%\n",
      "Epoch [14/32], Step [1200/2698], Loss: 0.5194, Accuracy: 87.50%\n",
      "Epoch [14/32], Step [1300/2698], Loss: 1.2831, Accuracy: 78.12%\n",
      "Epoch [14/32], Step [1400/2698], Loss: 0.3469, Accuracy: 96.88%\n",
      "Epoch [14/32], Step [1500/2698], Loss: 1.0818, Accuracy: 81.25%\n",
      "Epoch [14/32], Step [1600/2698], Loss: 0.8116, Accuracy: 81.25%\n",
      "Epoch [14/32], Step [1700/2698], Loss: 1.4086, Accuracy: 68.75%\n",
      "Epoch [14/32], Step [1800/2698], Loss: 0.8198, Accuracy: 87.50%\n",
      "Epoch [14/32], Step [1900/2698], Loss: 0.5347, Accuracy: 87.50%\n",
      "Epoch [14/32], Step [2000/2698], Loss: 0.4954, Accuracy: 93.75%\n",
      "Epoch [14/32], Step [2100/2698], Loss: 1.0313, Accuracy: 81.25%\n",
      "Epoch [14/32], Step [2200/2698], Loss: 1.1851, Accuracy: 75.00%\n",
      "Epoch [14/32], Step [2300/2698], Loss: 0.5914, Accuracy: 90.62%\n",
      "Epoch [14/32], Step [2400/2698], Loss: 1.1058, Accuracy: 81.25%\n",
      "Epoch [14/32], Step [2500/2698], Loss: 0.9409, Accuracy: 81.25%\n",
      "Epoch [14/32], Step [2600/2698], Loss: 0.7958, Accuracy: 81.25%\n",
      "Epoch [15/32], Step [100/2698], Loss: 0.7647, Accuracy: 81.25%\n",
      "Epoch [15/32], Step [200/2698], Loss: 0.5019, Accuracy: 87.50%\n",
      "Epoch [15/32], Step [300/2698], Loss: 0.5397, Accuracy: 87.50%\n",
      "Epoch [15/32], Step [400/2698], Loss: 0.5302, Accuracy: 84.38%\n",
      "Epoch [15/32], Step [500/2698], Loss: 0.3476, Accuracy: 87.50%\n",
      "Epoch [15/32], Step [600/2698], Loss: 0.9774, Accuracy: 78.12%\n",
      "Epoch [15/32], Step [700/2698], Loss: 0.7431, Accuracy: 81.25%\n",
      "Epoch [15/32], Step [800/2698], Loss: 0.9534, Accuracy: 78.12%\n",
      "Epoch [15/32], Step [900/2698], Loss: 1.0622, Accuracy: 75.00%\n",
      "Epoch [15/32], Step [1000/2698], Loss: 0.8174, Accuracy: 87.50%\n",
      "Epoch [15/32], Step [1100/2698], Loss: 1.1978, Accuracy: 75.00%\n",
      "Epoch [15/32], Step [1200/2698], Loss: 0.9994, Accuracy: 75.00%\n",
      "Epoch [15/32], Step [1300/2698], Loss: 1.2918, Accuracy: 65.62%\n",
      "Epoch [15/32], Step [1400/2698], Loss: 0.7491, Accuracy: 75.00%\n",
      "Epoch [15/32], Step [1500/2698], Loss: 0.9724, Accuracy: 84.38%\n",
      "Epoch [15/32], Step [1600/2698], Loss: 1.5559, Accuracy: 75.00%\n",
      "Epoch [15/32], Step [1700/2698], Loss: 1.1756, Accuracy: 68.75%\n",
      "Epoch [15/32], Step [1800/2698], Loss: 1.2889, Accuracy: 71.88%\n",
      "Epoch [15/32], Step [1900/2698], Loss: 1.0153, Accuracy: 81.25%\n",
      "Epoch [15/32], Step [2000/2698], Loss: 0.9606, Accuracy: 84.38%\n",
      "Epoch [15/32], Step [2100/2698], Loss: 0.5018, Accuracy: 93.75%\n",
      "Epoch [15/32], Step [2200/2698], Loss: 1.2361, Accuracy: 78.12%\n",
      "Epoch [15/32], Step [2300/2698], Loss: 1.3530, Accuracy: 68.75%\n",
      "Epoch [15/32], Step [2400/2698], Loss: 1.2943, Accuracy: 75.00%\n",
      "Epoch [15/32], Step [2500/2698], Loss: 0.5425, Accuracy: 87.50%\n",
      "Epoch [15/32], Step [2600/2698], Loss: 0.7065, Accuracy: 84.38%\n",
      "Epoch [16/32], Step [100/2698], Loss: 0.6480, Accuracy: 84.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/32], Step [200/2698], Loss: 0.2239, Accuracy: 93.75%\n",
      "Epoch [16/32], Step [300/2698], Loss: 1.1274, Accuracy: 84.38%\n",
      "Epoch [16/32], Step [400/2698], Loss: 1.2090, Accuracy: 84.38%\n",
      "Epoch [16/32], Step [500/2698], Loss: 0.7454, Accuracy: 78.12%\n",
      "Epoch [16/32], Step [600/2698], Loss: 1.2029, Accuracy: 78.12%\n",
      "Epoch [16/32], Step [700/2698], Loss: 1.0026, Accuracy: 75.00%\n",
      "Epoch [16/32], Step [800/2698], Loss: 1.6807, Accuracy: 68.75%\n",
      "Epoch [16/32], Step [900/2698], Loss: 0.6096, Accuracy: 87.50%\n",
      "Epoch [16/32], Step [1000/2698], Loss: 0.6375, Accuracy: 90.62%\n",
      "Epoch [16/32], Step [1100/2698], Loss: 0.8448, Accuracy: 78.12%\n",
      "Epoch [16/32], Step [1200/2698], Loss: 0.7303, Accuracy: 87.50%\n",
      "Epoch [16/32], Step [1300/2698], Loss: 0.6073, Accuracy: 93.75%\n",
      "Epoch [16/32], Step [1400/2698], Loss: 1.2138, Accuracy: 71.88%\n",
      "Epoch [16/32], Step [1500/2698], Loss: 0.1755, Accuracy: 100.00%\n",
      "Epoch [16/32], Step [1600/2698], Loss: 1.3015, Accuracy: 84.38%\n",
      "Epoch [16/32], Step [1700/2698], Loss: 0.6536, Accuracy: 87.50%\n",
      "Epoch [16/32], Step [1800/2698], Loss: 1.0437, Accuracy: 84.38%\n",
      "Epoch [16/32], Step [1900/2698], Loss: 0.7302, Accuracy: 87.50%\n",
      "Epoch [16/32], Step [2000/2698], Loss: 0.8790, Accuracy: 78.12%\n",
      "Epoch [16/32], Step [2100/2698], Loss: 0.4824, Accuracy: 93.75%\n",
      "Epoch [16/32], Step [2200/2698], Loss: 1.2739, Accuracy: 81.25%\n",
      "Epoch [16/32], Step [2300/2698], Loss: 0.5049, Accuracy: 90.62%\n",
      "Epoch [16/32], Step [2400/2698], Loss: 0.4206, Accuracy: 96.88%\n",
      "Epoch [16/32], Step [2500/2698], Loss: 0.8209, Accuracy: 81.25%\n",
      "Epoch [16/32], Step [2600/2698], Loss: 0.6730, Accuracy: 90.62%\n",
      "Epoch [17/32], Step [100/2698], Loss: 1.0209, Accuracy: 71.88%\n",
      "Epoch [17/32], Step [200/2698], Loss: 1.4646, Accuracy: 75.00%\n",
      "Epoch [17/32], Step [300/2698], Loss: 1.2948, Accuracy: 75.00%\n",
      "Epoch [17/32], Step [400/2698], Loss: 0.9641, Accuracy: 81.25%\n",
      "Epoch [17/32], Step [500/2698], Loss: 0.3891, Accuracy: 87.50%\n",
      "Epoch [17/32], Step [600/2698], Loss: 0.5348, Accuracy: 87.50%\n",
      "Epoch [17/32], Step [700/2698], Loss: 0.7795, Accuracy: 84.38%\n",
      "Epoch [17/32], Step [800/2698], Loss: 0.6387, Accuracy: 87.50%\n",
      "Epoch [17/32], Step [900/2698], Loss: 0.9979, Accuracy: 75.00%\n",
      "Epoch [17/32], Step [1000/2698], Loss: 1.0747, Accuracy: 87.50%\n",
      "Epoch [17/32], Step [1100/2698], Loss: 1.1761, Accuracy: 71.88%\n",
      "Epoch [17/32], Step [1200/2698], Loss: 0.8725, Accuracy: 78.12%\n",
      "Epoch [17/32], Step [1300/2698], Loss: 0.9442, Accuracy: 78.12%\n",
      "Epoch [17/32], Step [1400/2698], Loss: 0.8407, Accuracy: 84.38%\n",
      "Epoch [17/32], Step [1500/2698], Loss: 1.7048, Accuracy: 65.62%\n",
      "Epoch [17/32], Step [1600/2698], Loss: 0.8939, Accuracy: 84.38%\n",
      "Epoch [17/32], Step [1700/2698], Loss: 1.1433, Accuracy: 78.12%\n",
      "Epoch [17/32], Step [1800/2698], Loss: 0.3022, Accuracy: 100.00%\n",
      "Epoch [17/32], Step [1900/2698], Loss: 1.4532, Accuracy: 71.88%\n",
      "Epoch [17/32], Step [2000/2698], Loss: 0.8167, Accuracy: 81.25%\n",
      "Epoch [17/32], Step [2100/2698], Loss: 0.6395, Accuracy: 87.50%\n",
      "Epoch [17/32], Step [2200/2698], Loss: 0.5347, Accuracy: 87.50%\n",
      "Epoch [17/32], Step [2300/2698], Loss: 0.4792, Accuracy: 90.62%\n",
      "Epoch [17/32], Step [2400/2698], Loss: 1.1851, Accuracy: 78.12%\n",
      "Epoch [17/32], Step [2500/2698], Loss: 0.9770, Accuracy: 87.50%\n",
      "Epoch [17/32], Step [2600/2698], Loss: 0.9479, Accuracy: 84.38%\n",
      "Epoch [18/32], Step [100/2698], Loss: 0.6999, Accuracy: 84.38%\n",
      "Epoch [18/32], Step [200/2698], Loss: 1.2919, Accuracy: 71.88%\n",
      "Epoch [18/32], Step [300/2698], Loss: 0.8813, Accuracy: 81.25%\n",
      "Epoch [18/32], Step [400/2698], Loss: 0.9224, Accuracy: 81.25%\n",
      "Epoch [18/32], Step [500/2698], Loss: 0.9729, Accuracy: 75.00%\n",
      "Epoch [18/32], Step [600/2698], Loss: 1.0531, Accuracy: 78.12%\n",
      "Epoch [18/32], Step [700/2698], Loss: 0.7120, Accuracy: 90.62%\n",
      "Epoch [18/32], Step [800/2698], Loss: 0.7421, Accuracy: 87.50%\n",
      "Epoch [18/32], Step [900/2698], Loss: 0.5434, Accuracy: 87.50%\n",
      "Epoch [18/32], Step [1000/2698], Loss: 1.2075, Accuracy: 78.12%\n",
      "Epoch [18/32], Step [1100/2698], Loss: 1.0758, Accuracy: 78.12%\n",
      "Epoch [18/32], Step [1200/2698], Loss: 1.2864, Accuracy: 81.25%\n",
      "Epoch [18/32], Step [1300/2698], Loss: 0.4646, Accuracy: 87.50%\n",
      "Epoch [18/32], Step [1400/2698], Loss: 0.5576, Accuracy: 87.50%\n",
      "Epoch [18/32], Step [1500/2698], Loss: 0.9034, Accuracy: 84.38%\n",
      "Epoch [18/32], Step [1600/2698], Loss: 0.7518, Accuracy: 81.25%\n",
      "Epoch [18/32], Step [1700/2698], Loss: 0.5776, Accuracy: 81.25%\n",
      "Epoch [18/32], Step [1800/2698], Loss: 1.3513, Accuracy: 75.00%\n",
      "Epoch [18/32], Step [1900/2698], Loss: 0.3902, Accuracy: 87.50%\n",
      "Epoch [18/32], Step [2000/2698], Loss: 1.2087, Accuracy: 78.12%\n",
      "Epoch [18/32], Step [2100/2698], Loss: 0.6507, Accuracy: 87.50%\n",
      "Epoch [18/32], Step [2200/2698], Loss: 1.0142, Accuracy: 87.50%\n",
      "Epoch [18/32], Step [2300/2698], Loss: 1.0245, Accuracy: 81.25%\n",
      "Epoch [18/32], Step [2400/2698], Loss: 0.5140, Accuracy: 90.62%\n",
      "Epoch [18/32], Step [2500/2698], Loss: 0.6269, Accuracy: 84.38%\n",
      "Epoch [18/32], Step [2600/2698], Loss: 1.2315, Accuracy: 81.25%\n",
      "Epoch [19/32], Step [100/2698], Loss: 0.3989, Accuracy: 93.75%\n",
      "Epoch [19/32], Step [200/2698], Loss: 0.3127, Accuracy: 93.75%\n",
      "Epoch [19/32], Step [300/2698], Loss: 1.2914, Accuracy: 78.12%\n",
      "Epoch [19/32], Step [400/2698], Loss: 0.4139, Accuracy: 90.62%\n",
      "Epoch [19/32], Step [500/2698], Loss: 0.9590, Accuracy: 78.12%\n",
      "Epoch [19/32], Step [600/2698], Loss: 0.5655, Accuracy: 84.38%\n",
      "Epoch [19/32], Step [700/2698], Loss: 0.7545, Accuracy: 81.25%\n",
      "Epoch [19/32], Step [800/2698], Loss: 0.5525, Accuracy: 84.38%\n",
      "Epoch [19/32], Step [900/2698], Loss: 0.4966, Accuracy: 84.38%\n",
      "Epoch [19/32], Step [1000/2698], Loss: 1.1528, Accuracy: 75.00%\n",
      "Epoch [19/32], Step [1100/2698], Loss: 1.0470, Accuracy: 81.25%\n",
      "Epoch [19/32], Step [1200/2698], Loss: 0.8963, Accuracy: 78.12%\n",
      "Epoch [19/32], Step [1300/2698], Loss: 0.9578, Accuracy: 81.25%\n",
      "Epoch [19/32], Step [1400/2698], Loss: 0.6468, Accuracy: 90.62%\n",
      "Epoch [19/32], Step [1500/2698], Loss: 0.3632, Accuracy: 90.62%\n",
      "Epoch [19/32], Step [1600/2698], Loss: 0.6924, Accuracy: 87.50%\n",
      "Epoch [19/32], Step [1700/2698], Loss: 0.9400, Accuracy: 81.25%\n",
      "Epoch [19/32], Step [1800/2698], Loss: 0.6503, Accuracy: 84.38%\n",
      "Epoch [19/32], Step [1900/2698], Loss: 0.8771, Accuracy: 84.38%\n",
      "Epoch [19/32], Step [2000/2698], Loss: 1.4938, Accuracy: 75.00%\n",
      "Epoch [19/32], Step [2100/2698], Loss: 1.0115, Accuracy: 84.38%\n",
      "Epoch [19/32], Step [2200/2698], Loss: 0.6347, Accuracy: 87.50%\n",
      "Epoch [19/32], Step [2300/2698], Loss: 0.4303, Accuracy: 90.62%\n",
      "Epoch [19/32], Step [2400/2698], Loss: 1.2273, Accuracy: 84.38%\n",
      "Epoch [19/32], Step [2500/2698], Loss: 0.8127, Accuracy: 75.00%\n",
      "Epoch [19/32], Step [2600/2698], Loss: 0.8218, Accuracy: 78.12%\n",
      "Epoch [20/32], Step [100/2698], Loss: 0.5298, Accuracy: 93.75%\n",
      "Epoch [20/32], Step [200/2698], Loss: 1.1199, Accuracy: 78.12%\n",
      "Epoch [20/32], Step [300/2698], Loss: 1.0613, Accuracy: 81.25%\n",
      "Epoch [20/32], Step [400/2698], Loss: 0.5547, Accuracy: 87.50%\n",
      "Epoch [20/32], Step [500/2698], Loss: 0.4625, Accuracy: 93.75%\n",
      "Epoch [20/32], Step [600/2698], Loss: 0.7612, Accuracy: 87.50%\n",
      "Epoch [20/32], Step [700/2698], Loss: 0.3640, Accuracy: 87.50%\n",
      "Epoch [20/32], Step [800/2698], Loss: 1.1811, Accuracy: 78.12%\n",
      "Epoch [20/32], Step [900/2698], Loss: 1.2685, Accuracy: 78.12%\n",
      "Epoch [20/32], Step [1000/2698], Loss: 0.4600, Accuracy: 93.75%\n",
      "Epoch [20/32], Step [1100/2698], Loss: 0.5356, Accuracy: 93.75%\n",
      "Epoch [20/32], Step [1200/2698], Loss: 1.2974, Accuracy: 71.88%\n",
      "Epoch [20/32], Step [1300/2698], Loss: 0.5132, Accuracy: 90.62%\n",
      "Epoch [20/32], Step [1400/2698], Loss: 0.9966, Accuracy: 78.12%\n",
      "Epoch [20/32], Step [1500/2698], Loss: 0.8573, Accuracy: 84.38%\n",
      "Epoch [20/32], Step [1600/2698], Loss: 0.6586, Accuracy: 81.25%\n",
      "Epoch [20/32], Step [1700/2698], Loss: 0.5708, Accuracy: 90.62%\n",
      "Epoch [20/32], Step [1800/2698], Loss: 0.8218, Accuracy: 78.12%\n",
      "Epoch [20/32], Step [1900/2698], Loss: 0.8013, Accuracy: 87.50%\n",
      "Epoch [20/32], Step [2000/2698], Loss: 1.2165, Accuracy: 75.00%\n",
      "Epoch [20/32], Step [2100/2698], Loss: 1.1274, Accuracy: 71.88%\n",
      "Epoch [20/32], Step [2200/2698], Loss: 1.2402, Accuracy: 68.75%\n",
      "Epoch [20/32], Step [2300/2698], Loss: 0.5254, Accuracy: 90.62%\n",
      "Epoch [20/32], Step [2400/2698], Loss: 1.2560, Accuracy: 68.75%\n",
      "Epoch [20/32], Step [2500/2698], Loss: 1.0355, Accuracy: 78.12%\n",
      "Epoch [20/32], Step [2600/2698], Loss: 1.0322, Accuracy: 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/32], Step [100/2698], Loss: 0.7693, Accuracy: 87.50%\n",
      "Epoch [21/32], Step [200/2698], Loss: 0.6954, Accuracy: 84.38%\n",
      "Epoch [21/32], Step [300/2698], Loss: 1.2077, Accuracy: 78.12%\n",
      "Epoch [21/32], Step [400/2698], Loss: 1.4194, Accuracy: 78.12%\n",
      "Epoch [21/32], Step [500/2698], Loss: 0.8264, Accuracy: 75.00%\n",
      "Epoch [21/32], Step [600/2698], Loss: 0.6468, Accuracy: 84.38%\n",
      "Epoch [21/32], Step [700/2698], Loss: 0.5260, Accuracy: 90.62%\n",
      "Epoch [21/32], Step [800/2698], Loss: 0.6941, Accuracy: 81.25%\n",
      "Epoch [21/32], Step [900/2698], Loss: 0.4811, Accuracy: 84.38%\n",
      "Epoch [21/32], Step [1000/2698], Loss: 0.5732, Accuracy: 90.62%\n",
      "Epoch [21/32], Step [1100/2698], Loss: 0.5762, Accuracy: 90.62%\n",
      "Epoch [21/32], Step [1200/2698], Loss: 0.8238, Accuracy: 87.50%\n",
      "Epoch [21/32], Step [1300/2698], Loss: 1.0328, Accuracy: 78.12%\n",
      "Epoch [21/32], Step [1400/2698], Loss: 0.2667, Accuracy: 87.50%\n",
      "Epoch [21/32], Step [1500/2698], Loss: 1.0905, Accuracy: 78.12%\n",
      "Epoch [21/32], Step [1600/2698], Loss: 1.0158, Accuracy: 75.00%\n",
      "Epoch [21/32], Step [1700/2698], Loss: 1.1448, Accuracy: 75.00%\n",
      "Epoch [21/32], Step [1800/2698], Loss: 1.1180, Accuracy: 84.38%\n",
      "Epoch [21/32], Step [1900/2698], Loss: 1.0406, Accuracy: 78.12%\n",
      "Epoch [21/32], Step [2000/2698], Loss: 0.5877, Accuracy: 87.50%\n",
      "Epoch [21/32], Step [2100/2698], Loss: 1.2449, Accuracy: 78.12%\n",
      "Epoch [21/32], Step [2200/2698], Loss: 0.9604, Accuracy: 81.25%\n",
      "Epoch [21/32], Step [2300/2698], Loss: 0.9324, Accuracy: 81.25%\n",
      "Epoch [21/32], Step [2400/2698], Loss: 0.8251, Accuracy: 81.25%\n",
      "Epoch [21/32], Step [2500/2698], Loss: 1.0604, Accuracy: 81.25%\n",
      "Epoch [21/32], Step [2600/2698], Loss: 0.8027, Accuracy: 87.50%\n",
      "Epoch [22/32], Step [100/2698], Loss: 1.0879, Accuracy: 78.12%\n",
      "Epoch [22/32], Step [200/2698], Loss: 0.4920, Accuracy: 90.62%\n",
      "Epoch [22/32], Step [300/2698], Loss: 1.4037, Accuracy: 71.88%\n",
      "Epoch [22/32], Step [400/2698], Loss: 1.1846, Accuracy: 75.00%\n",
      "Epoch [22/32], Step [500/2698], Loss: 0.3177, Accuracy: 96.88%\n",
      "Epoch [22/32], Step [600/2698], Loss: 0.9340, Accuracy: 84.38%\n",
      "Epoch [22/32], Step [700/2698], Loss: 0.9757, Accuracy: 84.38%\n",
      "Epoch [22/32], Step [800/2698], Loss: 0.7854, Accuracy: 84.38%\n",
      "Epoch [22/32], Step [900/2698], Loss: 0.6549, Accuracy: 81.25%\n",
      "Epoch [22/32], Step [1000/2698], Loss: 0.5682, Accuracy: 87.50%\n",
      "Epoch [22/32], Step [1100/2698], Loss: 0.5803, Accuracy: 87.50%\n",
      "Epoch [22/32], Step [1200/2698], Loss: 1.0403, Accuracy: 78.12%\n",
      "Epoch [22/32], Step [1300/2698], Loss: 0.1877, Accuracy: 96.88%\n",
      "Epoch [22/32], Step [1400/2698], Loss: 1.1554, Accuracy: 71.88%\n",
      "Epoch [22/32], Step [1500/2698], Loss: 0.9372, Accuracy: 87.50%\n",
      "Epoch [22/32], Step [1600/2698], Loss: 0.1835, Accuracy: 96.88%\n",
      "Epoch [22/32], Step [1700/2698], Loss: 1.0716, Accuracy: 78.12%\n",
      "Epoch [22/32], Step [1800/2698], Loss: 1.5167, Accuracy: 75.00%\n",
      "Epoch [22/32], Step [1900/2698], Loss: 0.7473, Accuracy: 87.50%\n",
      "Epoch [22/32], Step [2000/2698], Loss: 0.6921, Accuracy: 93.75%\n",
      "Epoch [22/32], Step [2100/2698], Loss: 0.4428, Accuracy: 84.38%\n",
      "Epoch [22/32], Step [2200/2698], Loss: 1.2457, Accuracy: 84.38%\n",
      "Epoch [22/32], Step [2300/2698], Loss: 0.9096, Accuracy: 81.25%\n",
      "Epoch [22/32], Step [2400/2698], Loss: 0.4550, Accuracy: 90.62%\n",
      "Epoch [22/32], Step [2500/2698], Loss: 0.8480, Accuracy: 84.38%\n",
      "Epoch [22/32], Step [2600/2698], Loss: 1.0026, Accuracy: 84.38%\n",
      "Epoch [23/32], Step [100/2698], Loss: 0.6982, Accuracy: 90.62%\n",
      "Epoch [23/32], Step [200/2698], Loss: 1.5338, Accuracy: 68.75%\n",
      "Epoch [23/32], Step [300/2698], Loss: 0.4059, Accuracy: 90.62%\n",
      "Epoch [23/32], Step [400/2698], Loss: 0.6954, Accuracy: 84.38%\n",
      "Epoch [23/32], Step [500/2698], Loss: 0.5738, Accuracy: 90.62%\n",
      "Epoch [23/32], Step [600/2698], Loss: 1.1693, Accuracy: 78.12%\n",
      "Epoch [23/32], Step [700/2698], Loss: 1.1587, Accuracy: 75.00%\n",
      "Epoch [23/32], Step [800/2698], Loss: 1.2443, Accuracy: 75.00%\n",
      "Epoch [23/32], Step [900/2698], Loss: 0.5200, Accuracy: 87.50%\n",
      "Epoch [23/32], Step [1000/2698], Loss: 0.8266, Accuracy: 84.38%\n",
      "Epoch [23/32], Step [1100/2698], Loss: 1.1667, Accuracy: 71.88%\n",
      "Epoch [23/32], Step [1200/2698], Loss: 1.4103, Accuracy: 78.12%\n",
      "Epoch [23/32], Step [1300/2698], Loss: 0.9528, Accuracy: 84.38%\n",
      "Epoch [23/32], Step [1400/2698], Loss: 0.9309, Accuracy: 84.38%\n",
      "Epoch [23/32], Step [1500/2698], Loss: 0.7590, Accuracy: 81.25%\n",
      "Epoch [23/32], Step [1600/2698], Loss: 0.5356, Accuracy: 90.62%\n",
      "Epoch [23/32], Step [1700/2698], Loss: 0.8331, Accuracy: 81.25%\n",
      "Epoch [23/32], Step [1800/2698], Loss: 0.8363, Accuracy: 78.12%\n",
      "Epoch [23/32], Step [1900/2698], Loss: 0.7836, Accuracy: 84.38%\n",
      "Epoch [23/32], Step [2000/2698], Loss: 0.4954, Accuracy: 87.50%\n",
      "Epoch [23/32], Step [2100/2698], Loss: 0.5626, Accuracy: 87.50%\n",
      "Epoch [23/32], Step [2200/2698], Loss: 0.5267, Accuracy: 90.62%\n",
      "Epoch [23/32], Step [2300/2698], Loss: 0.8075, Accuracy: 87.50%\n",
      "Epoch [23/32], Step [2400/2698], Loss: 1.1541, Accuracy: 84.38%\n",
      "Epoch [23/32], Step [2500/2698], Loss: 1.0404, Accuracy: 78.12%\n",
      "Epoch [23/32], Step [2600/2698], Loss: 1.0002, Accuracy: 84.38%\n",
      "Epoch [24/32], Step [100/2698], Loss: 0.7400, Accuracy: 93.75%\n",
      "Epoch [24/32], Step [200/2698], Loss: 0.5496, Accuracy: 87.50%\n",
      "Epoch [24/32], Step [300/2698], Loss: 0.9875, Accuracy: 78.12%\n",
      "Epoch [24/32], Step [400/2698], Loss: 0.5362, Accuracy: 81.25%\n",
      "Epoch [24/32], Step [500/2698], Loss: 0.3754, Accuracy: 90.62%\n",
      "Epoch [24/32], Step [600/2698], Loss: 0.6788, Accuracy: 90.62%\n",
      "Epoch [24/32], Step [700/2698], Loss: 0.6451, Accuracy: 84.38%\n",
      "Epoch [24/32], Step [800/2698], Loss: 1.3933, Accuracy: 68.75%\n",
      "Epoch [24/32], Step [900/2698], Loss: 0.8675, Accuracy: 84.38%\n",
      "Epoch [24/32], Step [1000/2698], Loss: 1.1030, Accuracy: 78.12%\n",
      "Epoch [24/32], Step [1100/2698], Loss: 1.0140, Accuracy: 78.12%\n",
      "Epoch [24/32], Step [1200/2698], Loss: 1.0692, Accuracy: 84.38%\n",
      "Epoch [24/32], Step [1300/2698], Loss: 0.3444, Accuracy: 93.75%\n",
      "Epoch [24/32], Step [1400/2698], Loss: 0.9907, Accuracy: 81.25%\n",
      "Epoch [24/32], Step [1500/2698], Loss: 1.5781, Accuracy: 65.62%\n",
      "Epoch [24/32], Step [1600/2698], Loss: 0.7040, Accuracy: 81.25%\n",
      "Epoch [24/32], Step [1700/2698], Loss: 0.8254, Accuracy: 75.00%\n",
      "Epoch [24/32], Step [1800/2698], Loss: 1.0820, Accuracy: 78.12%\n",
      "Epoch [24/32], Step [1900/2698], Loss: 0.8221, Accuracy: 78.12%\n",
      "Epoch [24/32], Step [2000/2698], Loss: 0.7318, Accuracy: 87.50%\n",
      "Epoch [24/32], Step [2100/2698], Loss: 0.6586, Accuracy: 84.38%\n",
      "Epoch [24/32], Step [2200/2698], Loss: 1.1016, Accuracy: 84.38%\n",
      "Epoch [24/32], Step [2300/2698], Loss: 0.6354, Accuracy: 84.38%\n",
      "Epoch [24/32], Step [2400/2698], Loss: 0.5387, Accuracy: 90.62%\n",
      "Epoch [24/32], Step [2500/2698], Loss: 1.2941, Accuracy: 84.38%\n",
      "Epoch [24/32], Step [2600/2698], Loss: 0.6180, Accuracy: 87.50%\n",
      "Epoch [25/32], Step [100/2698], Loss: 0.7964, Accuracy: 84.38%\n",
      "Epoch [25/32], Step [200/2698], Loss: 0.9699, Accuracy: 81.25%\n",
      "Epoch [25/32], Step [300/2698], Loss: 0.7816, Accuracy: 81.25%\n",
      "Epoch [25/32], Step [400/2698], Loss: 0.5172, Accuracy: 90.62%\n",
      "Epoch [25/32], Step [500/2698], Loss: 1.8523, Accuracy: 75.00%\n",
      "Epoch [25/32], Step [600/2698], Loss: 0.9475, Accuracy: 81.25%\n",
      "Epoch [25/32], Step [700/2698], Loss: 1.0824, Accuracy: 75.00%\n",
      "Epoch [25/32], Step [800/2698], Loss: 0.8683, Accuracy: 81.25%\n",
      "Epoch [25/32], Step [900/2698], Loss: 0.7287, Accuracy: 84.38%\n",
      "Epoch [25/32], Step [1000/2698], Loss: 0.3569, Accuracy: 90.62%\n",
      "Epoch [25/32], Step [1100/2698], Loss: 0.8296, Accuracy: 84.38%\n",
      "Epoch [25/32], Step [1200/2698], Loss: 0.6754, Accuracy: 78.12%\n",
      "Epoch [25/32], Step [1300/2698], Loss: 0.8872, Accuracy: 71.88%\n",
      "Epoch [25/32], Step [1400/2698], Loss: 0.8096, Accuracy: 84.38%\n",
      "Epoch [25/32], Step [1500/2698], Loss: 0.3683, Accuracy: 96.88%\n",
      "Epoch [25/32], Step [1600/2698], Loss: 0.5633, Accuracy: 90.62%\n",
      "Epoch [25/32], Step [1700/2698], Loss: 0.9419, Accuracy: 87.50%\n",
      "Epoch [25/32], Step [1800/2698], Loss: 0.6120, Accuracy: 87.50%\n",
      "Epoch [25/32], Step [1900/2698], Loss: 1.2304, Accuracy: 78.12%\n",
      "Epoch [25/32], Step [2000/2698], Loss: 1.1415, Accuracy: 78.12%\n",
      "Epoch [25/32], Step [2100/2698], Loss: 1.4334, Accuracy: 78.12%\n",
      "Epoch [25/32], Step [2200/2698], Loss: 1.2303, Accuracy: 84.38%\n",
      "Epoch [25/32], Step [2300/2698], Loss: 1.1048, Accuracy: 78.12%\n",
      "Epoch [25/32], Step [2400/2698], Loss: 0.8427, Accuracy: 81.25%\n",
      "Epoch [25/32], Step [2500/2698], Loss: 0.8567, Accuracy: 78.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/32], Step [2600/2698], Loss: 0.8825, Accuracy: 81.25%\n",
      "Epoch [26/32], Step [100/2698], Loss: 0.4445, Accuracy: 90.62%\n",
      "Epoch [26/32], Step [200/2698], Loss: 0.4221, Accuracy: 90.62%\n",
      "Epoch [26/32], Step [300/2698], Loss: 0.8019, Accuracy: 78.12%\n",
      "Epoch [26/32], Step [400/2698], Loss: 0.4765, Accuracy: 90.62%\n",
      "Epoch [26/32], Step [500/2698], Loss: 0.4298, Accuracy: 87.50%\n",
      "Epoch [26/32], Step [600/2698], Loss: 0.9842, Accuracy: 78.12%\n",
      "Epoch [26/32], Step [700/2698], Loss: 0.9538, Accuracy: 78.12%\n",
      "Epoch [26/32], Step [800/2698], Loss: 0.5130, Accuracy: 93.75%\n",
      "Epoch [26/32], Step [900/2698], Loss: 0.6776, Accuracy: 84.38%\n",
      "Epoch [26/32], Step [1000/2698], Loss: 1.2586, Accuracy: 78.12%\n",
      "Epoch [26/32], Step [1100/2698], Loss: 0.6942, Accuracy: 84.38%\n",
      "Epoch [26/32], Step [1200/2698], Loss: 0.8338, Accuracy: 78.12%\n",
      "Epoch [26/32], Step [1300/2698], Loss: 0.5654, Accuracy: 90.62%\n",
      "Epoch [26/32], Step [1400/2698], Loss: 0.4313, Accuracy: 93.75%\n",
      "Epoch [26/32], Step [1500/2698], Loss: 0.6165, Accuracy: 84.38%\n",
      "Epoch [26/32], Step [1600/2698], Loss: 1.0869, Accuracy: 71.88%\n",
      "Epoch [26/32], Step [1700/2698], Loss: 0.7739, Accuracy: 81.25%\n",
      "Epoch [26/32], Step [1800/2698], Loss: 1.3418, Accuracy: 75.00%\n",
      "Epoch [26/32], Step [1900/2698], Loss: 0.7323, Accuracy: 78.12%\n",
      "Epoch [26/32], Step [2000/2698], Loss: 1.0655, Accuracy: 87.50%\n",
      "Epoch [26/32], Step [2100/2698], Loss: 1.0493, Accuracy: 75.00%\n",
      "Epoch [26/32], Step [2200/2698], Loss: 0.7920, Accuracy: 90.62%\n",
      "Epoch [26/32], Step [2300/2698], Loss: 0.3998, Accuracy: 96.88%\n",
      "Epoch [26/32], Step [2400/2698], Loss: 1.3006, Accuracy: 84.38%\n",
      "Epoch [26/32], Step [2500/2698], Loss: 0.9486, Accuracy: 84.38%\n",
      "Epoch [26/32], Step [2600/2698], Loss: 0.9141, Accuracy: 84.38%\n",
      "Epoch [27/32], Step [100/2698], Loss: 0.3570, Accuracy: 87.50%\n",
      "Epoch [27/32], Step [200/2698], Loss: 0.9610, Accuracy: 84.38%\n",
      "Epoch [27/32], Step [300/2698], Loss: 0.6610, Accuracy: 87.50%\n",
      "Epoch [27/32], Step [400/2698], Loss: 0.7940, Accuracy: 84.38%\n",
      "Epoch [27/32], Step [500/2698], Loss: 0.8893, Accuracy: 90.62%\n",
      "Epoch [27/32], Step [600/2698], Loss: 0.5752, Accuracy: 87.50%\n",
      "Epoch [27/32], Step [700/2698], Loss: 2.2714, Accuracy: 62.50%\n",
      "Epoch [27/32], Step [800/2698], Loss: 0.7847, Accuracy: 84.38%\n",
      "Epoch [27/32], Step [900/2698], Loss: 0.8569, Accuracy: 81.25%\n",
      "Epoch [27/32], Step [1000/2698], Loss: 1.1463, Accuracy: 78.12%\n",
      "Epoch [27/32], Step [1100/2698], Loss: 1.3664, Accuracy: 78.12%\n",
      "Epoch [27/32], Step [1200/2698], Loss: 1.8360, Accuracy: 68.75%\n",
      "Epoch [27/32], Step [1300/2698], Loss: 1.2242, Accuracy: 71.88%\n",
      "Epoch [27/32], Step [1400/2698], Loss: 0.7067, Accuracy: 78.12%\n",
      "Epoch [27/32], Step [1500/2698], Loss: 0.1754, Accuracy: 100.00%\n",
      "Epoch [27/32], Step [1600/2698], Loss: 0.7482, Accuracy: 84.38%\n",
      "Epoch [27/32], Step [1700/2698], Loss: 0.7892, Accuracy: 78.12%\n",
      "Epoch [27/32], Step [1800/2698], Loss: 1.5759, Accuracy: 68.75%\n",
      "Epoch [27/32], Step [1900/2698], Loss: 1.0112, Accuracy: 81.25%\n",
      "Epoch [27/32], Step [2000/2698], Loss: 1.1741, Accuracy: 68.75%\n",
      "Epoch [27/32], Step [2100/2698], Loss: 1.3005, Accuracy: 75.00%\n",
      "Epoch [27/32], Step [2200/2698], Loss: 0.6797, Accuracy: 87.50%\n",
      "Epoch [27/32], Step [2300/2698], Loss: 1.0757, Accuracy: 81.25%\n",
      "Epoch [27/32], Step [2400/2698], Loss: 0.3563, Accuracy: 93.75%\n",
      "Epoch [27/32], Step [2500/2698], Loss: 0.7584, Accuracy: 84.38%\n",
      "Epoch [27/32], Step [2600/2698], Loss: 0.8251, Accuracy: 81.25%\n",
      "Epoch [28/32], Step [100/2698], Loss: 0.6943, Accuracy: 84.38%\n",
      "Epoch [28/32], Step [200/2698], Loss: 0.7459, Accuracy: 87.50%\n",
      "Epoch [28/32], Step [300/2698], Loss: 1.0844, Accuracy: 81.25%\n",
      "Epoch [28/32], Step [400/2698], Loss: 0.9194, Accuracy: 75.00%\n",
      "Epoch [28/32], Step [500/2698], Loss: 1.1574, Accuracy: 65.62%\n",
      "Epoch [28/32], Step [600/2698], Loss: 1.1868, Accuracy: 78.12%\n",
      "Epoch [28/32], Step [700/2698], Loss: 0.5095, Accuracy: 93.75%\n",
      "Epoch [28/32], Step [800/2698], Loss: 0.9736, Accuracy: 81.25%\n",
      "Epoch [28/32], Step [900/2698], Loss: 0.9421, Accuracy: 78.12%\n",
      "Epoch [28/32], Step [1000/2698], Loss: 1.5987, Accuracy: 65.62%\n",
      "Epoch [28/32], Step [1100/2698], Loss: 0.2094, Accuracy: 96.88%\n",
      "Epoch [28/32], Step [1200/2698], Loss: 0.5474, Accuracy: 90.62%\n",
      "Epoch [28/32], Step [1300/2698], Loss: 0.8544, Accuracy: 81.25%\n",
      "Epoch [28/32], Step [1400/2698], Loss: 0.6433, Accuracy: 96.88%\n",
      "Epoch [28/32], Step [1500/2698], Loss: 1.0696, Accuracy: 75.00%\n",
      "Epoch [28/32], Step [1600/2698], Loss: 1.0568, Accuracy: 75.00%\n",
      "Epoch [28/32], Step [1700/2698], Loss: 1.0849, Accuracy: 75.00%\n",
      "Epoch [28/32], Step [1800/2698], Loss: 0.6796, Accuracy: 81.25%\n",
      "Epoch [28/32], Step [1900/2698], Loss: 0.7179, Accuracy: 78.12%\n",
      "Epoch [28/32], Step [2000/2698], Loss: 0.3572, Accuracy: 93.75%\n",
      "Epoch [28/32], Step [2100/2698], Loss: 0.7425, Accuracy: 87.50%\n",
      "Epoch [28/32], Step [2200/2698], Loss: 1.1429, Accuracy: 78.12%\n",
      "Epoch [28/32], Step [2300/2698], Loss: 0.4136, Accuracy: 93.75%\n",
      "Epoch [28/32], Step [2400/2698], Loss: 1.1310, Accuracy: 78.12%\n",
      "Epoch [28/32], Step [2500/2698], Loss: 0.9456, Accuracy: 78.12%\n",
      "Epoch [28/32], Step [2600/2698], Loss: 1.0415, Accuracy: 75.00%\n",
      "Epoch [29/32], Step [100/2698], Loss: 1.1637, Accuracy: 71.88%\n",
      "Epoch [29/32], Step [200/2698], Loss: 0.9309, Accuracy: 81.25%\n",
      "Epoch [29/32], Step [300/2698], Loss: 0.5345, Accuracy: 87.50%\n",
      "Epoch [29/32], Step [400/2698], Loss: 1.5132, Accuracy: 75.00%\n",
      "Epoch [29/32], Step [500/2698], Loss: 1.4742, Accuracy: 68.75%\n",
      "Epoch [29/32], Step [600/2698], Loss: 0.5607, Accuracy: 90.62%\n",
      "Epoch [29/32], Step [700/2698], Loss: 0.6399, Accuracy: 93.75%\n",
      "Epoch [29/32], Step [800/2698], Loss: 1.1043, Accuracy: 75.00%\n",
      "Epoch [29/32], Step [900/2698], Loss: 1.2789, Accuracy: 71.88%\n",
      "Epoch [29/32], Step [1000/2698], Loss: 0.9115, Accuracy: 84.38%\n",
      "Epoch [29/32], Step [1100/2698], Loss: 1.4370, Accuracy: 71.88%\n",
      "Epoch [29/32], Step [1200/2698], Loss: 1.0854, Accuracy: 84.38%\n",
      "Epoch [29/32], Step [1300/2698], Loss: 0.8445, Accuracy: 81.25%\n",
      "Epoch [29/32], Step [1400/2698], Loss: 1.7723, Accuracy: 75.00%\n",
      "Epoch [29/32], Step [1500/2698], Loss: 0.4748, Accuracy: 90.62%\n",
      "Epoch [29/32], Step [1600/2698], Loss: 1.3316, Accuracy: 68.75%\n",
      "Epoch [29/32], Step [1700/2698], Loss: 0.7643, Accuracy: 84.38%\n",
      "Epoch [29/32], Step [1800/2698], Loss: 0.6879, Accuracy: 90.62%\n",
      "Epoch [29/32], Step [1900/2698], Loss: 1.4032, Accuracy: 71.88%\n",
      "Epoch [29/32], Step [2000/2698], Loss: 0.8760, Accuracy: 81.25%\n",
      "Epoch [29/32], Step [2100/2698], Loss: 0.8985, Accuracy: 84.38%\n",
      "Epoch [29/32], Step [2200/2698], Loss: 1.0967, Accuracy: 75.00%\n",
      "Epoch [29/32], Step [2300/2698], Loss: 1.6282, Accuracy: 68.75%\n",
      "Epoch [29/32], Step [2400/2698], Loss: 0.8086, Accuracy: 87.50%\n",
      "Epoch [29/32], Step [2500/2698], Loss: 0.6496, Accuracy: 87.50%\n",
      "Epoch [29/32], Step [2600/2698], Loss: 0.9759, Accuracy: 81.25%\n",
      "Epoch [30/32], Step [100/2698], Loss: 1.1194, Accuracy: 81.25%\n",
      "Epoch [30/32], Step [200/2698], Loss: 0.3359, Accuracy: 93.75%\n",
      "Epoch [30/32], Step [300/2698], Loss: 1.5821, Accuracy: 65.62%\n",
      "Epoch [30/32], Step [400/2698], Loss: 0.6590, Accuracy: 87.50%\n",
      "Epoch [30/32], Step [500/2698], Loss: 0.2832, Accuracy: 96.88%\n",
      "Epoch [30/32], Step [600/2698], Loss: 0.8361, Accuracy: 75.00%\n",
      "Epoch [30/32], Step [700/2698], Loss: 1.0550, Accuracy: 84.38%\n",
      "Epoch [30/32], Step [800/2698], Loss: 0.9931, Accuracy: 78.12%\n",
      "Epoch [30/32], Step [900/2698], Loss: 1.0216, Accuracy: 84.38%\n",
      "Epoch [30/32], Step [1000/2698], Loss: 0.9003, Accuracy: 87.50%\n",
      "Epoch [30/32], Step [1100/2698], Loss: 0.7694, Accuracy: 90.62%\n",
      "Epoch [30/32], Step [1200/2698], Loss: 0.4649, Accuracy: 90.62%\n",
      "Epoch [30/32], Step [1300/2698], Loss: 0.5640, Accuracy: 81.25%\n",
      "Epoch [30/32], Step [1400/2698], Loss: 0.7488, Accuracy: 84.38%\n",
      "Epoch [30/32], Step [1500/2698], Loss: 0.4977, Accuracy: 87.50%\n",
      "Epoch [30/32], Step [1600/2698], Loss: 1.0254, Accuracy: 87.50%\n",
      "Epoch [30/32], Step [1700/2698], Loss: 0.9363, Accuracy: 84.38%\n",
      "Epoch [30/32], Step [1800/2698], Loss: 0.8638, Accuracy: 87.50%\n",
      "Epoch [30/32], Step [1900/2698], Loss: 1.2242, Accuracy: 84.38%\n",
      "Epoch [30/32], Step [2000/2698], Loss: 0.9676, Accuracy: 84.38%\n",
      "Epoch [30/32], Step [2100/2698], Loss: 0.8324, Accuracy: 84.38%\n",
      "Epoch [30/32], Step [2200/2698], Loss: 0.3611, Accuracy: 96.88%\n",
      "Epoch [30/32], Step [2300/2698], Loss: 0.8272, Accuracy: 84.38%\n",
      "Epoch [30/32], Step [2400/2698], Loss: 0.4166, Accuracy: 90.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/32], Step [2500/2698], Loss: 0.8579, Accuracy: 75.00%\n",
      "Epoch [30/32], Step [2600/2698], Loss: 0.3777, Accuracy: 87.50%\n",
      "Epoch [31/32], Step [100/2698], Loss: 0.3972, Accuracy: 96.88%\n",
      "Epoch [31/32], Step [200/2698], Loss: 1.0941, Accuracy: 75.00%\n",
      "Epoch [31/32], Step [300/2698], Loss: 1.0035, Accuracy: 75.00%\n",
      "Epoch [31/32], Step [400/2698], Loss: 0.5392, Accuracy: 90.62%\n",
      "Epoch [31/32], Step [500/2698], Loss: 1.0649, Accuracy: 71.88%\n",
      "Epoch [31/32], Step [600/2698], Loss: 0.9883, Accuracy: 81.25%\n",
      "Epoch [31/32], Step [700/2698], Loss: 1.2966, Accuracy: 81.25%\n",
      "Epoch [31/32], Step [800/2698], Loss: 0.3983, Accuracy: 90.62%\n",
      "Epoch [31/32], Step [900/2698], Loss: 0.5633, Accuracy: 87.50%\n",
      "Epoch [31/32], Step [1000/2698], Loss: 0.7907, Accuracy: 75.00%\n",
      "Epoch [31/32], Step [1100/2698], Loss: 0.7227, Accuracy: 84.38%\n",
      "Epoch [31/32], Step [1200/2698], Loss: 0.9780, Accuracy: 81.25%\n",
      "Epoch [31/32], Step [1300/2698], Loss: 1.1723, Accuracy: 75.00%\n",
      "Epoch [31/32], Step [1400/2698], Loss: 0.3424, Accuracy: 96.88%\n",
      "Epoch [31/32], Step [1500/2698], Loss: 1.0702, Accuracy: 81.25%\n",
      "Epoch [31/32], Step [1600/2698], Loss: 0.5776, Accuracy: 87.50%\n",
      "Epoch [31/32], Step [1700/2698], Loss: 0.4865, Accuracy: 84.38%\n",
      "Epoch [31/32], Step [1800/2698], Loss: 0.9120, Accuracy: 87.50%\n",
      "Epoch [31/32], Step [1900/2698], Loss: 1.1748, Accuracy: 78.12%\n",
      "Epoch [31/32], Step [2000/2698], Loss: 0.5516, Accuracy: 87.50%\n",
      "Epoch [31/32], Step [2100/2698], Loss: 0.4297, Accuracy: 90.62%\n",
      "Epoch [31/32], Step [2200/2698], Loss: 0.5729, Accuracy: 90.62%\n",
      "Epoch [31/32], Step [2300/2698], Loss: 0.8348, Accuracy: 84.38%\n",
      "Epoch [31/32], Step [2400/2698], Loss: 0.2068, Accuracy: 96.88%\n",
      "Epoch [31/32], Step [2500/2698], Loss: 0.6905, Accuracy: 87.50%\n",
      "Epoch [31/32], Step [2600/2698], Loss: 0.7560, Accuracy: 87.50%\n",
      "Epoch [32/32], Step [100/2698], Loss: 0.5127, Accuracy: 90.62%\n",
      "Epoch [32/32], Step [200/2698], Loss: 0.6203, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [300/2698], Loss: 0.6409, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [400/2698], Loss: 1.1072, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [500/2698], Loss: 1.0844, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [600/2698], Loss: 0.5780, Accuracy: 93.75%\n",
      "Epoch [32/32], Step [700/2698], Loss: 0.7259, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [800/2698], Loss: 0.8830, Accuracy: 78.12%\n",
      "Epoch [32/32], Step [900/2698], Loss: 0.9243, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [1000/2698], Loss: 1.4630, Accuracy: 75.00%\n",
      "Epoch [32/32], Step [1100/2698], Loss: 0.6940, Accuracy: 90.62%\n",
      "Epoch [32/32], Step [1200/2698], Loss: 0.2364, Accuracy: 93.75%\n",
      "Epoch [32/32], Step [1300/2698], Loss: 1.2870, Accuracy: 75.00%\n",
      "Epoch [32/32], Step [1400/2698], Loss: 0.6825, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [1500/2698], Loss: 0.6342, Accuracy: 87.50%\n",
      "Epoch [32/32], Step [1600/2698], Loss: 0.9910, Accuracy: 71.88%\n",
      "Epoch [32/32], Step [1700/2698], Loss: 0.3651, Accuracy: 93.75%\n",
      "Epoch [32/32], Step [1800/2698], Loss: 1.2036, Accuracy: 75.00%\n",
      "Epoch [32/32], Step [1900/2698], Loss: 0.6686, Accuracy: 87.50%\n",
      "Epoch [32/32], Step [2000/2698], Loss: 0.5862, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [2100/2698], Loss: 1.7174, Accuracy: 71.88%\n",
      "Epoch [32/32], Step [2200/2698], Loss: 0.5439, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [2300/2698], Loss: 1.1571, Accuracy: 84.38%\n",
      "Epoch [32/32], Step [2400/2698], Loss: 0.9082, Accuracy: 78.12%\n",
      "Epoch [32/32], Step [2500/2698], Loss: 0.7894, Accuracy: 87.50%\n",
      "Epoch [32/32], Step [2600/2698], Loss: 0.3983, Accuracy: 93.75%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d0e001d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.18156537859916 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for (images, labels) in test_loader:\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy: {} %'.format((correct / total) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b2a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
